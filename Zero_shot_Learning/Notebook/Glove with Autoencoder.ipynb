{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b44ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 5939 files [00:19, 309.54 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders, os\n",
    "\n",
    "# C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\Dataset\\CUB_KMean_Dataset\\ViT_data\n",
    "\n",
    "row_dataset_path = os.path.join('..', 'Dataset', 'CUB_KMean_Dataset', 'images')\n",
    "split_dataset_path = os.path.join('..', 'Dataset', 'data', 'CUB_data', 'images')\n",
    "\n",
    "splitfolders.ratio(row_dataset_path, split_dataset_path, seed=1111, ratio=(0.7, 0.15, 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e919d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "# Set dataset paths\n",
    "train_dir = os.path.join(split_dataset_path, 'train')\n",
    "val_dir = os.path.join(split_dataset_path, 'val') \n",
    "test_dir = os.path.join(split_dataset_path, 'test') \n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Image dimensions\n",
    "img_size = (224, 224)  # Resize to 128x128\n",
    "batch_size = 1\n",
    "latent_dim = 16  # Dimension of latent space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d498d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4146 images belonging to 101 classes.\n",
      "Found 872 images belonging to 101 classes.\n",
      "Found 921 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(train_dir, \n",
    "                                              target_size=img_size, \n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "val_generator = datagen.flow_from_directory(val_dir, \n",
    "                                            target_size=img_size, \n",
    "                                            batch_size=batch_size)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(test_dir, \n",
    "                                             target_size=img_size, \n",
    "                                             batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c653b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Autoencoder Model\n",
    "# input_img = Input(shape=(224, 224, 3))\n",
    "# input_shape = input_img.shape[1]\n",
    "\n",
    "# # Sample Test 1\n",
    "# # Encoder layers\n",
    "# encoded = Dense(32, activation='relu')(input_img)\n",
    "# encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "\n",
    "# # Decoder layers\n",
    "# decoded = Dense(32, activation='relu')(encoded)\n",
    "# decoded = Dense(input_shape, activation='sigmoid')(decoded) # num_classes\n",
    "\n",
    "# # Compile model\n",
    "# autoencoder = Model(input_img, decoded)\n",
    "# autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "\n",
    "# # Set steps_per_epoch correctly\n",
    "# steps_per_epoch = int(train_generator.samples // batch_size)\n",
    "# validation_steps = int(val_generator.samples // batch_size)\n",
    "\n",
    "# # Train model\n",
    "# autoencoder.fit(train_autoencoder_gen, \n",
    "#                 validation_data=val_autoencoder_gen, \n",
    "#                 epochs=10, \n",
    "#                 steps_per_epoch=steps_per_epoch, \n",
    "#                 validation_steps=validation_steps)\n",
    "\n",
    "# # Save model\n",
    "# autoencoder.save(\"autoencoder.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load and predict\n",
    "# autoencoder = tf.keras.models.load_model(\"autoencoder.h5\")\n",
    "# sample_images = next(test_generator)[:5]  # Get sample images\n",
    "# reconstructed_images = autoencoder.predict(sample_images)\n",
    "\n",
    "# # Display results\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "# for i in range(5):\n",
    "#     axes[0, i].imshow(sample_images[i])\n",
    "#     axes[0, i].axis('off')\n",
    "#     axes[1, i].imshow(reconstructed_images[i])\n",
    "#     axes[1, i].axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef850a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "301fae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62e772ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(input_shape):\n",
    "    # Encoder\n",
    "    encoder = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same'),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2), padding='same')\n",
    "    ])\n",
    "\n",
    "    # Decoder\n",
    "    decoder = models.Sequential([\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.UpSampling2D((2, 2)),\n",
    "        layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')  # Assuming 3-channel images\n",
    "    ])\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = models.Sequential([encoder, decoder])\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20f22676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4146 images belonging to 101 classes.\n",
      "Found 872 images belonging to 101 classes.\n",
      "Found 921 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set dataset paths\n",
    "train_dir = os.path.join(split_dataset_path, 'train')\n",
    "val_dir = os.path.join(split_dataset_path, 'val') \n",
    "test_dir = os.path.join(split_dataset_path, 'test') \n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 16\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'  # For autoencoder, we use 'input' as target is the same as input\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='input'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5b76213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "259/259 [==============================] - 482s 2s/step - loss: 0.0144 - accuracy: 0.6617 - val_loss: 0.0080 - val_accuracy: 0.7735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x224a21b9660>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (img_height, img_width, 3)\n",
    "autoencoder, encoder = build_autoencoder(input_shape)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_steps=val_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb49fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 291ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 1s 748ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 258ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n"
     ]
    }
   ],
   "source": [
    "def extract_features(generator, encoder):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for i in range(len(generator)):\n",
    "        x, _ = generator[i]  # Discard the target (input) for feature extraction\n",
    "        encoded_features = encoder.predict(x)\n",
    "        features.append(encoded_features)\n",
    "        labels.append(generator.classes[generator.index_array[i*batch_size:(i+1)*batch_size]])\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "train_features, train_labels = extract_features(train_generator, encoder)\n",
    "val_features, val_labels = extract_features(val_generator, encoder)\n",
    "test_features, test_labels = extract_features(test_generator, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da48e2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "260/260 [==============================] - 162s 505ms/step - loss: 4.7322 - accuracy: 0.0080 - val_loss: 4.6148 - val_accuracy: 0.0103\n",
      "Epoch 2/30\n",
      "260/260 [==============================] - 100s 383ms/step - loss: 4.6170 - accuracy: 0.0068 - val_loss: 4.6143 - val_accuracy: 0.0103\n",
      "Epoch 3/30\n",
      "260/260 [==============================] - 107s 412ms/step - loss: 4.6176 - accuracy: 0.0089 - val_loss: 4.6139 - val_accuracy: 0.0103\n",
      "Epoch 4/30\n",
      "260/260 [==============================] - 101s 390ms/step - loss: 4.6142 - accuracy: 0.0092 - val_loss: 4.6128 - val_accuracy: 0.0126\n",
      "Epoch 5/30\n",
      "260/260 [==============================] - 98s 376ms/step - loss: 4.6186 - accuracy: 0.0063 - val_loss: 4.6134 - val_accuracy: 0.0103\n",
      "Epoch 6/30\n",
      "260/260 [==============================] - 90s 348ms/step - loss: 4.6143 - accuracy: 0.0084 - val_loss: 4.6132 - val_accuracy: 0.0103\n",
      "Epoch 7/30\n",
      "260/260 [==============================] - 97s 374ms/step - loss: 4.6136 - accuracy: 0.0082 - val_loss: 4.6131 - val_accuracy: 0.0103\n",
      "Epoch 8/30\n",
      "260/260 [==============================] - 98s 376ms/step - loss: 4.6189 - accuracy: 0.0063 - val_loss: 4.6129 - val_accuracy: 0.0103\n",
      "Epoch 9/30\n",
      "260/260 [==============================] - 100s 384ms/step - loss: 4.6139 - accuracy: 0.0096 - val_loss: 4.6107 - val_accuracy: 0.0126\n",
      "Epoch 10/30\n",
      "260/260 [==============================] - 97s 375ms/step - loss: 4.6136 - accuracy: 0.0104 - val_loss: 4.6127 - val_accuracy: 0.0103\n",
      "Epoch 11/30\n",
      "260/260 [==============================] - 96s 369ms/step - loss: 4.6145 - accuracy: 0.0058 - val_loss: 4.6126 - val_accuracy: 0.0103\n",
      "Epoch 12/30\n",
      "260/260 [==============================] - 98s 377ms/step - loss: 4.6144 - accuracy: 0.0075 - val_loss: 4.6126 - val_accuracy: 0.0103\n",
      "Epoch 13/30\n",
      "260/260 [==============================] - 97s 375ms/step - loss: 4.6144 - accuracy: 0.0077 - val_loss: 4.6125 - val_accuracy: 0.0103\n",
      "Epoch 14/30\n",
      "260/260 [==============================] - 101s 387ms/step - loss: 4.6144 - accuracy: 0.0092 - val_loss: 4.6124 - val_accuracy: 0.0103\n",
      "Epoch 15/30\n",
      "260/260 [==============================] - 97s 372ms/step - loss: 4.6132 - accuracy: 0.0070 - val_loss: 4.6124 - val_accuracy: 0.0103\n",
      "Epoch 16/30\n",
      "260/260 [==============================] - 98s 377ms/step - loss: 4.6132 - accuracy: 0.0070 - val_loss: 4.6124 - val_accuracy: 0.0103\n",
      "Epoch 17/30\n",
      "260/260 [==============================] - 99s 381ms/step - loss: 4.6143 - accuracy: 0.0075 - val_loss: 4.6123 - val_accuracy: 0.0103\n",
      "Epoch 18/30\n",
      "260/260 [==============================] - 100s 384ms/step - loss: 4.6132 - accuracy: 0.0053 - val_loss: 4.6123 - val_accuracy: 0.0103\n",
      "Epoch 19/30\n",
      "260/260 [==============================] - 99s 382ms/step - loss: 4.6131 - accuracy: 0.0058 - val_loss: 4.6123 - val_accuracy: 0.0103\n",
      "Epoch 20/30\n",
      "260/260 [==============================] - 99s 381ms/step - loss: 4.6142 - accuracy: 0.0089 - val_loss: 4.6123 - val_accuracy: 0.0103\n",
      "Epoch 21/30\n",
      "260/260 [==============================] - 110s 424ms/step - loss: 4.6143 - accuracy: 0.0084 - val_loss: 4.6123 - val_accuracy: 0.0103\n",
      "Epoch 22/30\n",
      "260/260 [==============================] - 99s 381ms/step - loss: 4.6142 - accuracy: 0.0101 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 23/30\n",
      "260/260 [==============================] - 101s 389ms/step - loss: 4.6131 - accuracy: 0.0099 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 24/30\n",
      "260/260 [==============================] - 106s 407ms/step - loss: 4.6142 - accuracy: 0.0068 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 25/30\n",
      "260/260 [==============================] - 107s 413ms/step - loss: 4.6142 - accuracy: 0.0084 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 26/30\n",
      "260/260 [==============================] - 105s 405ms/step - loss: 4.6142 - accuracy: 0.0080 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 27/30\n",
      "260/260 [==============================] - 97s 374ms/step - loss: 4.6131 - accuracy: 0.0072 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 28/30\n",
      "260/260 [==============================] - 101s 388ms/step - loss: 4.6131 - accuracy: 0.0068 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 29/30\n",
      "260/260 [==============================] - 101s 388ms/step - loss: 4.6131 - accuracy: 0.0075 - val_loss: 4.6122 - val_accuracy: 0.0103\n",
      "Epoch 30/30\n",
      "260/260 [==============================] - 95s 364ms/step - loss: 4.6131 - accuracy: 0.0070 - val_loss: 4.6122 - val_accuracy: 0.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x224c7e0ea70>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 101\n",
    "\n",
    "# Define classifier\n",
    "classifier = models.Sequential([\n",
    "    layers.Input(shape=train_features.shape[1:]),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train classifier\n",
    "classifier.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    epochs=30,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38425e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "classifier.save('classification_model.h5')\n",
    "encoder.save('encoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19a5b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicted Class: 9\n",
      "Found 4146 files belonging to 101 classes.\n",
      "Predicted Class Name: Barn_Swallow\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def classify_single_image(image_path, encoder, classifier):\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Extract features using encoder\n",
    "    encoded_features = encoder.predict(img_array)\n",
    "\n",
    "    # Predict class\n",
    "    predictions = classifier.predict(encoded_features)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_path = os.path.join(train_dir, 'Acadian_Flycatcher', 'Acadian_Flycatcher_0003_29094.jpg')\n",
    "predicted_class = classify_single_image(image_path, encoder, classifier)\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir)\n",
    "class_names = train_dataset.class_names\n",
    "predicted_class_name = class_names[predicted_class]\n",
    "print(f\"Predicted Class Name: {predicted_class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd9a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d3ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d060b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf793a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f70888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95d358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e36a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016eb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
