{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57303226",
   "metadata": {},
   "source": [
    "# Gensim Fasttext\n",
    "\n",
    "Gensim provides a convenient implementation of FastText, which can be used to train word vectors on a custom corpus or to use pre-trained models for various tasks such as finding similar words and computing similarity scores between words.\n",
    "\n",
    "### Installing Gensim\n",
    "\n",
    "> pip install gensim\n",
    "\n",
    "### Using Gensim FastText\n",
    "\n",
    "Here are the key steps to use Gensim FastText:\n",
    "\n",
    "1. Loading a Pre-trained Model\n",
    "2. Training a FastText Model on a Custom Corpus\n",
    "3. Finding Similar Words\n",
    "4. Computing Similarity Scores Between Words\n",
    "\n",
    "### Links\n",
    "\n",
    "[Migrating-from-Gensim-3.x-to-4](https://github.com/piskvorky/gensim/wiki/Migrating-from-Gensim-3.x-to-4)\n",
    "\n",
    "[cub-200-2011_paper](https://paperswithcode.com/dataset/cub-200-2011)\n",
    "\n",
    "[cub-200-2011_dataset](https://www.kaggle.com/datasets/wenewone/cub2002011?resource=download)\n",
    "\n",
    "[Microsoft C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04785f",
   "metadata": {},
   "source": [
    "### 1. Loading a Pre-trained Model\n",
    "\n",
    "Gensim provides a way to load pre-trained FastText models. For example, you can load the pre-trained FastText model provided by Facebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70a6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=300, 999999 keys>\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained FastText model\n",
    "model = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef73e23",
   "metadata": {},
   "source": [
    "### 2. Training a FastText Model on a Custom Corpus\n",
    "\n",
    "You can also train a FastText model on your custom corpus. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e6e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences : [['african_buffalo'], ['alligator'], ['amphibian'], ['amur_leopard'], ['ants'], ['bear'], ['bird'], ['blue_whale'], ['bobcat'], ['cat'], ['chimp'], ['chimpanzee'], ['cow'], ['dog'], ['dolphin'], [], ['eagle'], ['elephant'], ['fish'], ['frog'], ['giant'], ['giant_panda'], ['goat'], ['gorilla'], ['hen'], ['horse'], ['killer_whale'], ['lion'], ['lizard'], ['monkey'], ['mouse'], ['orangutan'], ['ostrich'], ['ox'], ['panda'], ['polar_bear'], ['rabbit'], ['rat'], ['rhino'], ['rhinoceros'], ['rhinoceroses'], ['seal'], ['sealskin'], ['siamese_cat'], ['skunk'], ['spider_monkey'], ['squirrel'], ['tiger'], ['turtle'], ['walrus'], ['whale'], ['bird'], ['fish'], ['lion'], ['tiger'], ['bull']] \n",
      "\n",
      "model : FastText<vocab=51, vector_size=300, alpha=0.025> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Example sentences\n",
    "# sentences = [\n",
    "#     \"Cats and dogs are both popular household pets, yet cats are more independent and often prefer solitude. They share some hunting instincts with their larger feline cousins like lions and tigers.\",\n",
    "#     \"Dogs and cats are common pets, but dogs are known for their loyalty and tendency to form strong bonds with humans. Unlike solitary big cats, dogs are social animals that thrive in packs.\",\n",
    "#     \"Horses, like elephants, have been domesticated to assist humans in various tasks. However, horses are known for their speed and agility, whereas elephants are prized for their strength and intelligence.\",\n",
    "#     \"Lions and tigers are both apex predators, but lions are social animals living in prides. In contrast, tigers are solitary creatures, only coming together during mating or to raise cubs.\",\n",
    "#     \"Tigers share their powerful physique and hunting prowess with lions. Unlike the social lions, tigers are mostly solitary, showcasing a stark behavioral difference between the two big cats.\",\n",
    "#     \"Elephants, similar to horses, have been used by humans for labor due to their strength. Elephants, however, are highly intelligent with complex social structures, unlike the more individually task-oriented horses.\",\n",
    "# ]\n",
    "sentences = [\n",
    "    'african_buffalo', 'alligator', 'amphibian', 'amur_leopard', \n",
    "    'ants', 'bear', 'bird', 'blue_whale', 'bobcat', 'cat', 'chimp', \n",
    "    'chimpanzee', 'cow', 'dog', 'dolphin', 'domestic_water_buffalo', \n",
    "    'eagle', 'elephant', 'fish', 'frog', 'giant', 'giant_panda', 'goat', \n",
    "    'gorilla', 'hen', 'horse', 'killer_whale', 'lion', 'lizard', 'monkey', \n",
    "    'mouse', 'orangutan', 'ostrich', 'ox', 'panda', 'polar_bear', 'rabbit', \n",
    "    'rat', 'rhino', 'rhinoceros', 'rhinoceroses', 'seal', 'sealskin', \n",
    "    'siamese_cat', 'skunk', 'spider_monkey', 'squirrel', 'tiger', 'turtle', \n",
    "    'walrus', 'whale', 'bird', 'fish', 'lion', 'tiger', 'bull'\n",
    "]\n",
    "\n",
    "# Preprocess sentences\n",
    "sentences = [simple_preprocess(sentence) for sentence in sentences]\n",
    "\n",
    "print(f\"sentences : {sentences} \\n\")\n",
    "\n",
    "# Train FastText model\n",
    "model = FastText(sentences, vector_size=300, window=5, min_count=1, epochs=10000)\n",
    "\n",
    "print(f\"model : {model} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d89e93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.fasttext.FastTextKeyedVectors at 0x17e562e5600>, 51, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv, len(model.wv), len(model.wv[0]) # model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fc12d",
   "metadata": {},
   "source": [
    "### 3. Finding Similar Words\n",
    "\n",
    "Once you have a trained or pre-trained model, you can find similar words using the `most_similar` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a5230d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bobcat', 0.2737165093421936), ('goat', 0.15198037028312683), ('bird', 0.12732714414596558), ('ostrich', 0.09741493314504623), ('seal', 0.09225074201822281), ('siamese_cat', 0.08397927135229111), ('african_buffalo', 0.08353123813867569), ('ants', 0.06892219930887222), ('walrus', 0.05629545822739601), ('rat', 0.055904362350702286)]\n"
     ]
    }
   ],
   "source": [
    "# Find similar words to 'machine'\n",
    "similar_words = model.wv.most_similar('cat', topn=10)\n",
    "\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af887b8",
   "metadata": {},
   "source": [
    "### 4. Computing Similarity Scores Between Words\n",
    "\n",
    "You can compute similarity scores between two words using the `similarity` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd1a2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2737165\n",
      "0.08397927  *\n",
      "0.1394797  *\n",
      "0.012166994\n",
      "0.055904355\n",
      "0.007804998\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity score between 'cat' and 'dog'\n",
    "similarity_score = model.wv.similarity('cat', 'bobcat')\n",
    "print(similarity_score)\n",
    "\n",
    "similarity_score = model.wv.similarity('cat', 'siamese_cat')\n",
    "print(similarity_score, ' *')\n",
    "\n",
    "similarity_score = model.wv.similarity('cat', 'siamese cat')\n",
    "print(similarity_score, ' *')\n",
    "\n",
    "similarity_score = model.wv.similarity('cat', 'dog')\n",
    "print(similarity_score)\n",
    "\n",
    "similarity_score = model.wv.similarity('cat', 'rat')\n",
    "print(similarity_score)\n",
    "\n",
    "similarity_score = model.wv.similarity('cat', 'ferret')\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db912ee6",
   "metadata": {},
   "source": [
    "# Gensim Word2Vec\n",
    "\n",
    "### Using Gensim Word2Vec\n",
    "\n",
    "Here are the key steps to use Gensim Word2Vec:\n",
    "\n",
    "1. Training a Word2Vec Model on a Custom Corpus\n",
    "2. Finding Similar Words\n",
    "3. Computing Similarity Scores Between Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6523c3c",
   "metadata": {},
   "source": [
    "### 1. Training a Word2Vec Model on a Custom Corpus\n",
    "\n",
    "You can train a Word2Vec model on your custom corpus. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af52a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences : [['african_buffalo'], ['alligator'], ['amphibian'], ['amur_leopard'], ['ants'], ['bear'], ['bird'], ['blue_whale'], ['bobcat'], ['cat'], ['chimp'], ['chimpanzee'], ['cow'], ['dog'], ['dolphin'], [], ['eagle'], ['elephant'], ['fish'], ['frog'], ['giant'], ['giant_panda'], ['goat'], ['gorilla'], ['hen'], ['horse'], ['killer_whale'], ['lion'], ['lizard'], ['monkey'], ['mouse'], ['orangutan'], ['ostrich'], ['ox'], ['panda'], ['polar_bear'], ['rabbit'], ['rat'], ['rhino'], ['rhinoceros'], ['rhinoceroses'], ['seal'], ['sealskin'], ['siamese_cat'], ['skunk'], ['spider_monkey'], ['squirrel'], ['tiger'], ['turtle'], ['walrus'], ['whale'], ['bird'], ['fish'], ['lion'], ['tiger'], ['bull']] \n",
      "\n",
      "model : Word2Vec<vocab=51, vector_size=300, alpha=0.025> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\n",
    "    'african_buffalo', 'alligator', 'amphibian', 'amur_leopard', \n",
    "    'ants', 'bear', 'bird', 'blue_whale', 'bobcat', 'cat', 'chimp', \n",
    "    'chimpanzee', 'cow', 'dog', 'dolphin', 'domestic_water_buffalo', \n",
    "    'eagle', 'elephant', 'fish', 'frog', 'giant', 'giant_panda', 'goat', \n",
    "    'gorilla', 'hen', 'horse', 'killer_whale', 'lion', 'lizard', 'monkey', \n",
    "    'mouse', 'orangutan', 'ostrich', 'ox', 'panda', 'polar_bear', 'rabbit', \n",
    "    'rat', 'rhino', 'rhinoceros', 'rhinoceroses', 'seal', 'sealskin', \n",
    "    'siamese_cat', 'skunk', 'spider_monkey', 'squirrel', 'tiger', 'turtle', \n",
    "    'walrus', 'whale', 'bird', 'fish', 'lion', 'tiger', 'bull'\n",
    "]\n",
    "\n",
    "# Preprocess sentences\n",
    "sentences = [simple_preprocess(sentence) for sentence in sentences]\n",
    "print(f\"sentences : {sentences} \\n\")\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, epochs=10000)\n",
    "print(f\"model : {model} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7817e4",
   "metadata": {},
   "source": [
    "### 2. Finding Similar Words\n",
    "\n",
    "Once you have a trained model, you can find similar words using the most_similar method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62fc0751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'cat':\n",
      "ants: 0.11463356018066406\n",
      "goat: 0.10705526173114777\n",
      "rhinoceros: 0.09309180825948715\n",
      "monkey: 0.09122835099697113\n",
      "rhino: 0.08179710805416107\n",
      "rabbit: 0.07725443691015244\n",
      "orangutan: 0.07632383704185486\n",
      "bear: 0.07548326253890991\n",
      "rhinoceroses: 0.06613056361675262\n",
      "chimpanzee: 0.042745448648929596\n"
     ]
    }
   ],
   "source": [
    "# Find similar words to 'cat'\n",
    "similar_words = model.wv.most_similar('cat', topn=10)\n",
    "print(\"Most similar words to 'cat':\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e920c777",
   "metadata": {},
   "source": [
    "### 3. Computing Similarity Scores Between Words\n",
    "\n",
    "You can compute similarity scores between two words using the similarity method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3dbd170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between 'cat' and 'bobcat': -0.01531929150223732\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity score between 'cat' and 'bobcat'\n",
    "similarity_score = model.wv.similarity('cat', 'bobcat')\n",
    "print(f\"Similarity score between 'cat' and 'bobcat': {similarity_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6871d93",
   "metadata": {},
   "source": [
    "# Gensim Doc2Vec\n",
    "\n",
    "### Using Gensim Doc2Vec\n",
    "\n",
    "Here are the key steps to use Gensim Doc2Vec:\n",
    "\n",
    "1. Prepare the Data\n",
    "2. Train the Doc2Vec Model\n",
    "3. Finding Similar Documents\n",
    "4. Computing Similarity Scores Between Documents\n",
    "\n",
    "\n",
    "[Practical Guide To Doc2Vec](https://spotintelligence.com/2023/09/06/doc2vec/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7018c3",
   "metadata": {},
   "source": [
    "### 1. Prepare the Data\n",
    "\n",
    "You need to preprocess your documents and tag them appropriately. Gensim's TaggedDocument is used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b04fe8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged_documents : [TaggedDocument(words=['african_buffalo'], tags=[0]), TaggedDocument(words=['alligator'], tags=[1]), TaggedDocument(words=['amphibian'], tags=[2]), TaggedDocument(words=['amur_leopard'], tags=[3]), TaggedDocument(words=['ants'], tags=[4]), TaggedDocument(words=['bear'], tags=[5]), TaggedDocument(words=['bird'], tags=[6]), TaggedDocument(words=['blue_whale'], tags=[7]), TaggedDocument(words=['bobcat'], tags=[8]), TaggedDocument(words=['cat'], tags=[9]), TaggedDocument(words=['chimp'], tags=[10]), TaggedDocument(words=['chimpanzee'], tags=[11]), TaggedDocument(words=['cow'], tags=[12]), TaggedDocument(words=['dog'], tags=[13]), TaggedDocument(words=['dolphin'], tags=[14]), TaggedDocument(words=[], tags=[15]), TaggedDocument(words=['eagle'], tags=[16]), TaggedDocument(words=['elephant'], tags=[17]), TaggedDocument(words=['fish'], tags=[18]), TaggedDocument(words=['frog'], tags=[19]), TaggedDocument(words=['giant'], tags=[20]), TaggedDocument(words=['giant_panda'], tags=[21]), TaggedDocument(words=['goat'], tags=[22]), TaggedDocument(words=['gorilla'], tags=[23]), TaggedDocument(words=['hen'], tags=[24]), TaggedDocument(words=['horse'], tags=[25]), TaggedDocument(words=['killer_whale'], tags=[26]), TaggedDocument(words=['lion'], tags=[27]), TaggedDocument(words=['lizard'], tags=[28]), TaggedDocument(words=['monkey'], tags=[29]), TaggedDocument(words=['mouse'], tags=[30]), TaggedDocument(words=['orangutan'], tags=[31]), TaggedDocument(words=['ostrich'], tags=[32]), TaggedDocument(words=['ox'], tags=[33]), TaggedDocument(words=['panda'], tags=[34]), TaggedDocument(words=['polar_bear'], tags=[35]), TaggedDocument(words=['rabbit'], tags=[36]), TaggedDocument(words=['rat'], tags=[37]), TaggedDocument(words=['rhino'], tags=[38]), TaggedDocument(words=['rhinoceros'], tags=[39]), TaggedDocument(words=['rhinoceroses'], tags=[40]), TaggedDocument(words=['seal'], tags=[41]), TaggedDocument(words=['sealskin'], tags=[42]), TaggedDocument(words=['siamese_cat'], tags=[43]), TaggedDocument(words=['skunk'], tags=[44]), TaggedDocument(words=['spider_monkey'], tags=[45]), TaggedDocument(words=['squirrel'], tags=[46]), TaggedDocument(words=['tiger'], tags=[47]), TaggedDocument(words=['turtle'], tags=[48]), TaggedDocument(words=['walrus'], tags=[49]), TaggedDocument(words=['whale'], tags=[50]), TaggedDocument(words=['bird'], tags=[51]), TaggedDocument(words=['fish'], tags=[52]), TaggedDocument(words=['lion'], tags=[53]), TaggedDocument(words=['tiger'], tags=[54]), TaggedDocument(words=['bull'], tags=[55])]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Example documents\n",
    "documents = [\n",
    "    'african_buffalo', 'alligator', 'amphibian', 'amur_leopard', \n",
    "    'ants', 'bear', 'bird', 'blue_whale', 'bobcat', 'cat', 'chimp', \n",
    "    'chimpanzee', 'cow', 'dog', 'dolphin', 'domestic_water_buffalo', \n",
    "    'eagle', 'elephant', 'fish', 'frog', 'giant', 'giant_panda', 'goat', \n",
    "    'gorilla', 'hen', 'horse', 'killer_whale', 'lion', 'lizard', 'monkey', \n",
    "    'mouse', 'orangutan', 'ostrich', 'ox', 'panda', 'polar_bear', 'rabbit', \n",
    "    'rat', 'rhino', 'rhinoceros', 'rhinoceroses', 'seal', 'sealskin', \n",
    "    'siamese_cat', 'skunk', 'spider_monkey', 'squirrel', 'tiger', 'turtle', \n",
    "    'walrus', 'whale', 'bird', 'fish', 'lion', 'tiger', 'bull'\n",
    "]\n",
    "\n",
    "# Preprocess and tag documents\n",
    "tagged_documents = [TaggedDocument(simple_preprocess(doc), [i]) for i, doc in enumerate(documents)]\n",
    "print(f\"tagged_documents : {tagged_documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bd747",
   "metadata": {},
   "source": [
    "### 2. Train the Doc2Vec Model\n",
    "\n",
    "Now, you can train a Doc2Vec model using the preprocessed and tagged documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8933cd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model : Doc2Vec<dm/m,d300,n5,w5,s0.001,t3>\n"
     ]
    }
   ],
   "source": [
    "# Train Doc2Vec model\n",
    "model = Doc2Vec(tagged_documents, vector_size=300, window=5, min_count=1, epochs=10000)\n",
    "print(f\"model : {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39756066",
   "metadata": {},
   "source": [
    "### 3. Finding Similar Documents\n",
    "\n",
    "You can find documents that are similar to a given document by using the dv.most_similar method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2470a5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar documents to the first document:\n",
      "Document 34: 0.40884047746658325\n",
      "Document 6: 0.3998793661594391\n",
      "Document 35: 0.39414697885513306\n",
      "Document 53: 0.3926096558570862\n",
      "Document 27: 0.390058308839798\n"
     ]
    }
   ],
   "source": [
    "# Find similar documents to the first document\n",
    "similar_docs = model.dv.most_similar(9, topn=5)\n",
    "print(\"Most similar documents to the first document:\")\n",
    "for doc_id, score in similar_docs:\n",
    "    print(f\"Document {doc_id}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e7fca",
   "metadata": {},
   "source": [
    "### 4. Computing Similarity Scores Between Documents\n",
    "\n",
    "To compute the similarity score between two documents, you can use the dv.similarity method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73a7ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between the first and second document: 0.3201076090335846\n"
     ]
    }
   ],
   "source": [
    "# Compute similarity score between the first and second document\n",
    "similarity_score = model.dv.similarity(9, 8)\n",
    "print(f\"Similarity score between the first and second document: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c905ebc",
   "metadata": {},
   "source": [
    "# BERT\n",
    "\n",
    "Finding similar words using BERT involves extracting embeddings for words and then calculating similarity between these embeddings. BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained transformer model that generates context-aware word embeddings. Here's how you can find similar words using BERT:\n",
    "\n",
    "### Steps to Find Similar Words Using BERT\n",
    "\n",
    "1. Install Necessary Libraries\n",
    "2. Load Pre-trained BERT Model and Tokenizer\n",
    "3. Get Embeddings for Words\n",
    "4. Compute Similarity Scores\n",
    "5. Find Most Similar Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74676e",
   "metadata": {},
   "source": [
    "### 1. Install Necessary Libraries\n",
    "\n",
    "First, ensure you have the necessary libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c81c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e77527",
   "metadata": {},
   "source": [
    "### 2. Load Pre-trained BERT Model and Tokenizer\n",
    "\n",
    "Load a pre-trained BERT model and its tokenizer from the Hugging Face library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f30ec3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer : BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "} \n",
      "\n",
      "model : BertModel(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (token_type_embeddings): Embedding(2, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x BertLayer(\n",
      "        (attention): BertAttention(\n",
      "          (self): BertSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ") \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "print(f\"tokenizer : {tokenizer} \\n\")\n",
    "\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "print(f\"model : {model} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a45c2",
   "metadata": {},
   "source": [
    "### 3. Get Embeddings for Words\n",
    "\n",
    "Define a function to get the embeddings for a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8508960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word, tokenizer, model):\n",
    "    inputs = tokenizer(word, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use the output from the last hidden state\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    # Get the mean of the token embeddings\n",
    "    word_embedding = embeddings.mean(dim=1)\n",
    "    return word_embedding.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bba2f1",
   "metadata": {},
   "source": [
    "### 4. Compute Similarity Scores\n",
    "\n",
    "Compute cosine similarity between word embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71a46127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return 1 - cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a2ff1",
   "metadata": {},
   "source": [
    "### 5. Find Most Similar Words\n",
    "\n",
    "Find the most similar words in a given list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba3d999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'cat':\n",
      "cat: 1\n",
      "squirrel: 0.9277651906013489\n",
      "rabbit: 0.9275433421134949\n",
      "monkey: 0.9177643060684204\n",
      "tiger: 0.912547767162323\n"
     ]
    }
   ],
   "source": [
    "def find_similar_words(target_word, word_list, tokenizer, model, top_n=5):\n",
    "    target_embedding = get_word_embedding(target_word, tokenizer, model)\n",
    "    similarities = []\n",
    "    for word in word_list:\n",
    "        word_embedding = get_word_embedding(word, tokenizer, model)\n",
    "        similarity = cosine_similarity(target_embedding, word_embedding)\n",
    "        similarities.append((word, similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Example word list\n",
    "word_list = [\n",
    "    'african_buffalo', 'alligator', 'amphibian', 'amur_leopard', \n",
    "    'ants', 'bear', 'bird', 'blue_whale', 'bobcat', 'cat', 'chimp', \n",
    "    'chimpanzee', 'cow', 'dog', 'dolphin', 'domestic_water_buffalo', \n",
    "    'eagle', 'elephant', 'fish', 'frog', 'giant', 'giant_panda', 'goat', \n",
    "    'gorilla', 'hen', 'horse', 'killer_whale', 'lion', 'lizard', 'monkey', \n",
    "    'mouse', 'orangutan', 'ostrich', 'ox', 'panda', 'polar_bear', 'rabbit', \n",
    "    'rat', 'rhino', 'rhinoceros', 'rhinoceroses', 'seal', 'sealskin', \n",
    "    'siamese_cat', 'skunk', 'spider_monkey', 'squirrel', 'tiger', 'turtle', \n",
    "    'walrus', 'whale', 'bird', 'fish', 'lion', 'tiger', 'bull'\n",
    "]\n",
    "\n",
    "# Find words similar to 'cat'\n",
    "similar_words = find_similar_words(\"cat\", word_list, tokenizer, model)\n",
    "print(\"Most similar words to 'cat':\")\n",
    "for word, score in similar_words:\n",
    "    print(f\"{word}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882bf67",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "To find similar words using an autoencoder, you can follow these steps:\n",
    "\n",
    "1. Prepare the Data: Create a dataset of word embeddings.\n",
    "2. Build an Autoencoder: Design an autoencoder model.\n",
    "3. Train the Autoencoder: Train the model on your dataset.\n",
    "4. Encode Words: Use the trained encoder to get compressed representations (latent vectors) of words.\n",
    "5. Find Similar Words: Calculate similarity between these latent vectors to find similar words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecfc4f",
   "metadata": {},
   "source": [
    "### 1. Prepare the Data\n",
    "\n",
    "First, you need a dataset of word embeddings. You can use pre-trained word vectors such as GloVe or Word2Vec. For simplicity, let's use GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b8d1fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Download GloVe embeddings\n",
    "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "urllib.request.urlretrieve(glove_url, \"glove.6B.zip\")\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"glove.6B.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"glove.6B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83b4a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_index : <class 'dict'> \n",
      "\n",
      "sentence_embeddings : <class 'dict'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example custom dataset\n",
    "custom_sentences = [\n",
    "    'african_buffalo', 'alligator', 'amphibian', 'amur_leopard', \n",
    "    'ants', 'bear', 'bird', 'blue_whale', 'bobcat', 'cat', 'chimp', \n",
    "    'chimpanzee', 'cow', 'dog', 'dolphin', 'domestic_water_buffalo', \n",
    "    'eagle', 'elephant', 'fish', 'frog', 'giant', 'giant_panda', 'goat', \n",
    "    'gorilla', 'hen', 'horse', 'killer_whale', 'lion', 'lizard', 'monkey', \n",
    "    'mouse', 'orangutan', 'ostrich', 'ox', 'panda', 'polar_bear', 'rabbit', \n",
    "    'rat', 'rhino', 'rhinoceros', 'rhinoceroses', 'seal', 'sealskin', \n",
    "    'siamese_cat', 'skunk', 'spider_monkey', 'squirrel', 'tiger', 'turtle', \n",
    "    'walrus', 'whale', 'bird', 'fish', 'lion', 'tiger', 'bull'\n",
    "]\n",
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = load_glove_embeddings(\"glove.6B/glove.6B.50d.txt\")  # Using 50d GloVe embeddings\n",
    "print(f\"embeddings_index : {type(embeddings_index)} \\n\")\n",
    "\n",
    "# Convert sentences to embeddings\n",
    "def sentence_to_embedding(sentence, embeddings_index):\n",
    "    words = simple_preprocess(sentence)\n",
    "    valid_words = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if valid_words:\n",
    "        return np.mean(valid_words, axis=0)\n",
    "    else:\n",
    "        return np.zeros(50)\n",
    "\n",
    "sentence_embeddings = np.array([sentence_to_embedding(sentence, embeddings_index) for sentence in custom_sentences])\n",
    "print(f\"sentence_embeddings : {type(embeddings_index)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6531c50",
   "metadata": {},
   "source": [
    "### 2: Build the Autoencoder Model\n",
    "\n",
    "Design the autoencoder model using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aefaa2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define the size of the input and latent space\n",
    "input_dim = 50  # Dimension of GloVe embeddings\n",
    "latent_dim = 16  # Dimension of latent space\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# Encoder layers\n",
    "encoded = Dense(32, activation='relu')(input_layer)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder layers\n",
    "decoded = Dense(32, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a4e600",
   "metadata": {},
   "source": [
    "### 3: Train the Autoencoder\n",
    "\n",
    "Train the autoencoder on your custom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fcfa6edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "25/25 [==============================] - 1s 10ms/step - loss: 0.5857 - val_loss: 0.6852\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5293 - val_loss: 0.5780\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4044 - val_loss: 0.4347\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3243 - val_loss: 0.3831\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3024 - val_loss: 0.3733\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2956 - val_loss: 0.3669\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2916 - val_loss: 0.3654\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2882 - val_loss: 0.3659\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2849 - val_loss: 0.3614\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2815 - val_loss: 0.3609\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2794 - val_loss: 0.3593\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2761 - val_loss: 0.3574\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2739 - val_loss: 0.3556\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2710 - val_loss: 0.3516\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2689 - val_loss: 0.3517\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2658 - val_loss: 0.3479\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2640 - val_loss: 0.3441\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2615 - val_loss: 0.3416\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2592 - val_loss: 0.3405\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2564 - val_loss: 0.3363\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2544 - val_loss: 0.3348\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2524 - val_loss: 0.3321\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2506 - val_loss: 0.3293\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2488 - val_loss: 0.3274\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.3251\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2451 - val_loss: 0.3239\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2438 - val_loss: 0.3224\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2427 - val_loss: 0.3216\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2414 - val_loss: 0.3206\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2400 - val_loss: 0.3188\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2393 - val_loss: 0.3191\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2376 - val_loss: 0.3165\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2367 - val_loss: 0.3162\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2360 - val_loss: 0.3148\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2358 - val_loss: 0.3143\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2345 - val_loss: 0.3148\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2339 - val_loss: 0.3136\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2331 - val_loss: 0.3124\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2327 - val_loss: 0.3127\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2322 - val_loss: 0.3138\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2318 - val_loss: 0.3113\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2311 - val_loss: 0.3128\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2307 - val_loss: 0.3109\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2301 - val_loss: 0.3110\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2300 - val_loss: 0.3116\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2293 - val_loss: 0.3109\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2289 - val_loss: 0.3114\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2284 - val_loss: 0.3098\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2284 - val_loss: 0.3106\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2280 - val_loss: 0.3102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17de41fcb50>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "autoencoder.fit(sentence_embeddings, sentence_embeddings, epochs=50, batch_size=2, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b8774",
   "metadata": {},
   "source": [
    "### 4: Encode Words\n",
    "\n",
    "Use the trained encoder to get latent representations of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11dda56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Encode sentences to get their latent representations\n",
    "sentence_latents = encoder.predict(sentence_embeddings)\n",
    "# print(f\"sentence_latents : {sentence_latents}\")\n",
    "\n",
    "# Create a dictionary to map sentences to their latent representations\n",
    "sentence_to_latent = {i: sentence_latents[i] for i in range(len(custom_sentences))}\n",
    "# print(f\"sentence_to_latent : {sentence_to_latent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380ec5f",
   "metadata": {},
   "source": [
    "### 5: Find Similar Sentences\n",
    "\n",
    "Calculate similarity between latent vectors to find similar sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80e7a7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar sentences to the first sentence:\n",
      "Sentence: skunk - Similarity: 0.9701589345932007\n",
      "Sentence: walrus - Similarity: 0.9549508690834045\n",
      "Sentence: rhinoceros - Similarity: 0.9532212615013123\n",
      "Sentence: squirrel - Similarity: 0.9429846405982971\n",
      "Sentence: rhinoceroses - Similarity: 0.9255936145782471\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def find_similar_sentences(target_sentence_index, sentence_to_latent, top_n=5):\n",
    "    target_latent = sentence_to_latent[target_sentence_index]\n",
    "    similarities = []\n",
    "    for index, latent in sentence_to_latent.items():\n",
    "        if index != target_sentence_index:\n",
    "            similarity = 1 - cosine(target_latent, latent)\n",
    "            similarities.append((index, similarity))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "# Find sentences similar to the first sentence\n",
    "similar_sentences = find_similar_sentences(8, sentence_to_latent)\n",
    "print(\"Most similar sentences to the first sentence:\")\n",
    "for index, score in similar_sentences:\n",
    "    print(f\"Sentence: {custom_sentences[index]} - Similarity: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555d6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99701e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaedca56",
   "metadata": {},
   "source": [
    "# ZSL\n",
    "\n",
    "Zero-shot learning (ZSL) is a machine learning paradigm where a model is trained to recognize objects or perform tasks that it has never seen before during training. Instead of relying solely on labeled examples for every possible category, ZSL leverages auxiliary information (such as semantic attributes, descriptions, or relationships) to make predictions about unseen classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914570e9",
   "metadata": {},
   "source": [
    "# Code for Zero-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444d73a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Zero_shot_Learning\\venv_zsl\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load a pre-trained ResNet50 model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet50(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cdist\n",
    "import fasttext\n",
    "\n",
    "# Load a pre-trained ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Function to extract visual features\n",
    "def extract_features(image_path):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    features = model.predict(image)\n",
    "    return features\n",
    "\n",
    "# Load FastText word vectors\n",
    "fasttext_model = fasttext.load_model('cc.en.300.bin')\n",
    "# from gensim.models.keyedvectors import KeyedVectors\n",
    "# import gensim.downloader as api\n",
    "# fast_text_vectors = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "# fast_text_vectors.save('fstwk_1.d2v')\n",
    "# fast_text_vectors = KeyedVectors.load(\"fstwk_1.d2v\")\n",
    "\n",
    "# Example seen and unseen classes\n",
    "seen_classes = ['cat', 'dog', 'horse']\n",
    "unseen_classes = ['lion', 'tiger', 'elephant']\n",
    "\n",
    "# Get word vectors for classes\n",
    "def get_class_vectors(classes):\n",
    "    return np.array([fasttext_model.get_word_vector(cls) for cls in classes])\n",
    "\n",
    "# Normalize the word vectors\n",
    "seen_vectors = normalize(get_class_vectors(seen_classes))\n",
    "unseen_vectors = normalize(get_class_vectors(unseen_classes))\n",
    "\n",
    "# Function to perform zero-shot classification\n",
    "def zero_shot_classify(image_path):\n",
    "    features = extract_features(image_path)\n",
    "    features = normalize(features)\n",
    "    distances = cdist(features, unseen_vectors, metric='cosine')\n",
    "    return unseen_classes[np.argmin(distances)]\n",
    "\n",
    "# Example usage\n",
    "image_path = 'Sample_Images\\cat1.jpg'\n",
    "predicted_class = zero_shot_classify(image_path)\n",
    "print(f'Predicted class: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076fe16",
   "metadata": {},
   "source": [
    "Conditional Autoencoders (CAEs) are a variant of autoencoders where additional information is used to condition the encoding and decoding processes. This conditioning can help the autoencoder learn more structured and relevant representations based on the context provided by the additional information.\n",
    "\n",
    "### Autoencoders Recap\n",
    "\n",
    "Autoencoders are neural networks designed to learn efficient representations (encodings) of input data, typically for the purpose of dimensionality reduction or data denoising.\n",
    "\n",
    "Components:\n",
    "- Encoder: Compresses the input data into a latent-space representation.\n",
    "- Decoder: Reconstructs the input data from the latent representation.\n",
    "\n",
    "### Conditional Autoencoders\n",
    "In a Conditional Autoencoder, the input data is conditioned on some additional information (conditions). This information can be labels, attributes, or any other relevant context that influences the encoding and decoding processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7ac74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377655d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead62f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30cd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf8bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
