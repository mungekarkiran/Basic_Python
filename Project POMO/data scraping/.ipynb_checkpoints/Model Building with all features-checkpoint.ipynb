{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.pandas.set_option('display.max_columns',None)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import docx\n",
    "from docx.shared import Inches\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>tempC_7to8</th>\n",
       "      <th>tempC_1to2</th>\n",
       "      <th>tempC_6to7</th>\n",
       "      <th>tempC_avg(0C)</th>\n",
       "      <th>Relative humidity_7to8</th>\n",
       "      <th>Relative humidity_1to2</th>\n",
       "      <th>Relative humidity_6to7</th>\n",
       "      <th>Relative humidity_avg(%)</th>\n",
       "      <th>windspeedKmph_7to8</th>\n",
       "      <th>windspeedKmph_1to2</th>\n",
       "      <th>windspeedKmph_6to7</th>\n",
       "      <th>windspeedKmph_avg(Km/h)</th>\n",
       "      <th>pressureMB_7to8</th>\n",
       "      <th>pressureMB_1to2</th>\n",
       "      <th>pressureMB_6to7</th>\n",
       "      <th>pressureMB_avg</th>\n",
       "      <th>precipMM_7to8</th>\n",
       "      <th>precipMM_1to2</th>\n",
       "      <th>precipMM_6to7</th>\n",
       "      <th>precipMM_avg(mm)</th>\n",
       "      <th>weatherDesc_7to8</th>\n",
       "      <th>weatherDesc_1to2</th>\n",
       "      <th>weatherDesc_6to7</th>\n",
       "      <th>weatherDesc</th>\n",
       "      <th>Sunshine Hours</th>\n",
       "      <th>%_soil_moisure</th>\n",
       "      <th>soil_pH</th>\n",
       "      <th>water_pH</th>\n",
       "      <th>water_TDS_mgpl</th>\n",
       "      <th>Label (Disease Yes/No)</th>\n",
       "      <th>Type of Disease (Bacterial Blight/Telya)</th>\n",
       "      <th>Anthracnose</th>\n",
       "      <th>Fruit Spot/ Rot</th>\n",
       "      <th>Fusarium Wilt</th>\n",
       "      <th>Fruit Borer / Blight Blora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1015</td>\n",
       "      <td>1012</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>45</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1015</td>\n",
       "      <td>1013</td>\n",
       "      <td>1015</td>\n",
       "      <td>1014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>45</td>\n",
       "      <td>6.77</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>61</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1017</td>\n",
       "      <td>1014</td>\n",
       "      <td>1015</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>41</td>\n",
       "      <td>6.76</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1016</td>\n",
       "      <td>1012</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>43</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.43</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1013</td>\n",
       "      <td>1010</td>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>44</td>\n",
       "      <td>6.53</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation  date  month  year  tempC_7to8  tempC_1to2  tempC_6to7  \\\n",
       "0  2010-01-01     1      1  2010          20          30          20   \n",
       "1  2010-01-02     2      1  2010          23          29          23   \n",
       "2  2010-01-03     3      1  2010          24          27          21   \n",
       "3  2010-01-04     4      1  2010          23          29          20   \n",
       "4  2010-01-05     5      1  2010          22          30          21   \n",
       "\n",
       "   tempC_avg(0C)  Relative humidity_7to8  Relative humidity_1to2  \\\n",
       "0             23                      42                      33   \n",
       "1             25                      49                      40   \n",
       "2             24                      61                      50   \n",
       "3             24                      57                      30   \n",
       "4             24                      48                      34   \n",
       "\n",
       "   Relative humidity_6to7  Relative humidity_avg(%)  windspeedKmph_7to8  \\\n",
       "0                      59                        44                   9   \n",
       "1                      62                        50                   9   \n",
       "2                      78                        63                   4   \n",
       "3                      52                        46                   5   \n",
       "4                      54                        45                   6   \n",
       "\n",
       "   windspeedKmph_1to2  windspeedKmph_6to7  windspeedKmph_avg(Km/h)  \\\n",
       "0                   2                   4                        5   \n",
       "1                   3                   3                        5   \n",
       "2                   8                   6                        6   \n",
       "3                   7                   6                        6   \n",
       "4                   2                   4                        4   \n",
       "\n",
       "   pressureMB_7to8  pressureMB_1to2  pressureMB_6to7  pressureMB_avg  \\\n",
       "0             1015             1012             1013            1013   \n",
       "1             1015             1013             1015            1014   \n",
       "2             1017             1014             1015            1015   \n",
       "3             1016             1012             1013            1013   \n",
       "4             1013             1010             1012            1011   \n",
       "\n",
       "   precipMM_7to8  precipMM_1to2  precipMM_6to7  precipMM_avg(mm)  \\\n",
       "0            0.0            0.0            0.0               0.0   \n",
       "1            0.0            0.0            0.0               0.0   \n",
       "2            0.0            0.0            0.0               0.0   \n",
       "3            0.0            0.0            0.0               0.0   \n",
       "4            0.0            0.0            0.0               0.0   \n",
       "\n",
       "   weatherDesc_7to8  weatherDesc_1to2  weatherDesc_6to7  weatherDesc  \\\n",
       "0                 5                 5                 5            5   \n",
       "1                 5                 4                 4            4   \n",
       "2                 4                 4                 4            4   \n",
       "3                 5                 5                 5            5   \n",
       "4                 5                 5                 5            5   \n",
       "\n",
       "   Sunshine Hours  %_soil_moisure  soil_pH  water_pH  water_TDS_mgpl  \\\n",
       "0             9.8              45     6.91      7.18          1709.0   \n",
       "1             9.8              45     6.77      7.66          1707.0   \n",
       "2             9.8              41     6.76      7.44          1707.0   \n",
       "3             9.8              43     7.10      7.43          1708.0   \n",
       "4             9.8              44     6.53      8.05          1709.0   \n",
       "\n",
       "   Label (Disease Yes/No)  Type of Disease (Bacterial Blight/Telya)  \\\n",
       "0                       0                                         0   \n",
       "1                       1                                         1   \n",
       "2                       0                                         0   \n",
       "3                       0                                         0   \n",
       "4                       0                                         0   \n",
       "\n",
       "   Anthracnose  Fruit Spot/ Rot  Fusarium Wilt  Fruit Borer / Blight Blora  \n",
       "0            0                0              0                           0  \n",
       "1            1                0              0                           0  \n",
       "2            0                0              0                           0  \n",
       "3            0                0              0                           0  \n",
       "4            0                0              0                           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'part6\\Historical Weather Data 2010-2021_preprocessed_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['observation', 'date', 'month', 'year', 'tempC_7to8', 'tempC_1to2', 'tempC_6to7', 'tempC_avg(0C)', 'Relative humidity_7to8', 'Relative humidity_1to2', 'Relative humidity_6to7', 'Relative humidity_avg(%)', 'windspeedKmph_7to8', 'windspeedKmph_1to2', 'windspeedKmph_6to7', 'windspeedKmph_avg(Km/h)', 'pressureMB_7to8', 'pressureMB_1to2', 'pressureMB_6to7', 'pressureMB_avg', 'precipMM_7to8', 'precipMM_1to2', 'precipMM_6to7', 'precipMM_avg(mm)', 'weatherDesc_7to8', 'weatherDesc_1to2', 'weatherDesc_6to7', 'weatherDesc', 'Sunshine Hours', '%_soil_moisure', 'soil_pH', 'water_pH', 'water_TDS_mgpl', 'Label (Disease Yes/No)', 'Type of Disease (Bacterial Blight/Telya)', 'Anthracnose', 'Fruit Spot/ Rot', 'Fusarium Wilt', 'Fruit Borer / Blight Blora']\n"
     ]
    }
   ],
   "source": [
    "# columns name \n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['date', 'month', 'year', 'tempC_7to8', 'tempC_1to2', 'tempC_6to7', 'tempC_avg(0C)', \n",
    "        'Relative humidity_7to8', 'Relative humidity_1to2', 'Relative humidity_6to7', 'Relative humidity_avg(%)', \n",
    "        'windspeedKmph_7to8', 'windspeedKmph_1to2', 'windspeedKmph_6to7', 'windspeedKmph_avg(Km/h)', \n",
    "        'pressureMB_7to8', 'pressureMB_1to2', 'pressureMB_6to7', 'pressureMB_avg', 'precipMM_7to8', 'precipMM_1to2', \n",
    "        'precipMM_6to7', 'precipMM_avg(mm)', 'weatherDesc_7to8', 'weatherDesc_1to2', 'weatherDesc_6to7', 'weatherDesc', \n",
    "        'Sunshine Hours', '%_soil_moisure', 'soil_pH', 'water_pH', 'water_TDS_mgpl']]\n",
    "\n",
    "Y = df[['Type of Disease (Bacterial Blight/Telya)', 'Anthracnose', 'Fruit Spot/ Rot', \n",
    "        'Fusarium Wilt', 'Fruit Borer / Blight Blora']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_Classifier = LogisticRegression(max_iter=1000, random_state=3757)  \n",
    "# knn_Classifier = KNeighborsClassifier(n_jobs=-1, n_neighbors=5, p=2, weights='uniform')  \n",
    "# nb_Classifier = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "# svm_Classifier = SVC(gamma='auto')\n",
    "# dt_Classifier = DecisionTreeClassifier(random_state=3757)\n",
    "# rf_Classifier = RandomForestClassifier(n_jobs=-1, random_state=3757)\n",
    "# gb_Classifier = GradientBoostingClassifier(random_state=3757)\n",
    "# ab_Classifier = AdaBoostClassifier(random_state=3757)\n",
    "\n",
    "# classifiers = [lr_Classifier, knn_Classifier, nb_Classifier, svm_Classifier, dt_Classifier, \n",
    "#                rf_Classifier, gb_Classifier, ab_Classifier]\n",
    "\n",
    "model_name = ['lr_Classifier', 'knn_Classifier', 'nb_Classifier', 'svm_Classifier', 'dt_Classifier', \n",
    "              'rf_Classifier', 'gb_Classifier', 'ab_Classifier']\n",
    "\n",
    "\n",
    "lr_Classifier = LogisticRegression(max_iter=1000, random_state=3757)  \n",
    "knn_Classifier = KNeighborsClassifier(n_jobs=-1, n_neighbors=5, p=2, weights='uniform')  \n",
    "nb_Classifier = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "svm_Classifier = SVC(gamma='auto')\n",
    "dt_Classifier = DecisionTreeClassifier(random_state=3757)\n",
    "rf_Classifier = RandomForestClassifier(n_jobs=-1, random_state=3757)\n",
    "gb_Classifier = GradientBoostingClassifier(random_state=3757)\n",
    "ab_Classifier = AdaBoostClassifier(random_state=3757)\n",
    "\n",
    "classifiers = [lr_Classifier, knn_Classifier, nb_Classifier, svm_Classifier, dt_Classifier, \n",
    "               rf_Classifier, gb_Classifier, ab_Classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from POMO_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\test\\Basic_Python\\Project POMO\\data scraping\\POMO_classifier.py:156: RuntimeWarning: divide by zero encountered in floor_divide\n",
      "  y_pred_new = np.nan_to_num(and_of_pred // or_of_pred)\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report on Training dataset : \n",
      "Accuracy_score: 57.94 %\n",
      "Loss: 42.06 %\n",
      "Zero_one_loss: 42.06 %\n",
      "Hamming_loss: 14.75 %\n",
      "ML_confusion_matrix:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.05       824\n",
      "           1       1.00      0.00      0.01       475\n",
      "           2       1.00      0.02      0.04       320\n",
      "           3       0.00      0.00      0.00        73\n",
      "           4       1.00      0.04      0.08       540\n",
      "\n",
      "   micro avg       1.00      0.02      0.04      2232\n",
      "   macro avg       0.80      0.02      0.03      2232\n",
      "weighted avg       0.97      0.02      0.04      2232\n",
      " samples avg       0.01      0.01      0.01      2232\n",
      "\n",
      "Classification Report on Testing dataset : \n",
      "Accuracy_score: 99.84 %\n",
      "Loss: 0.16 %\n",
      "Zero_one_loss: 0.16 %\n",
      "Hamming_loss: 0.03 %\n",
      "ML_confusion_matrix:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       350\n",
      "           1       1.00      1.00      1.00       201\n",
      "           2       1.00      1.00      1.00       144\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00       247\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       972\n",
      "   macro avg       1.00      1.00      1.00       972\n",
      "weighted avg       1.00      1.00      1.00       972\n",
      " samples avg       0.44      0.44      0.44       972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\test\\Basic_Python\\Project POMO\\data scraping\\POMO_classifier.py:156: RuntimeWarning: divide by zero encountered in floor_divide\n",
      "  y_pred_new = np.nan_to_num(and_of_pred // or_of_pred)\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RESULT_FILE_PATH': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-09-02-21-31-53\\\\Docs\\\\MultiLabelModel_result.csv'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ensemble_voting_classifier((X_train, y_train), (X_test, y_test), classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\test\\Basic_Python\\Project POMO\\data scraping\\POMO_classifier.py:156: RuntimeWarning: divide by zero encountered in floor_divide\n",
      "  y_pred_new = np.nan_to_num(and_of_pred // or_of_pred)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_ensemble_voting_classifier(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1269, 1269)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "Accuracy_score: 99.84 %\n",
      "Loss: 0.16 %\n",
      "Zero_one_loss: 0.16 %\n",
      "Hamming_loss: 0.03 %\n",
      "ML_confusion_matrix:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       350\n",
      "           1       1.00      1.00      1.00       201\n",
      "           2       1.00      1.00      1.00       144\n",
      "           3       1.00      1.00      1.00        30\n",
      "           4       1.00      1.00      1.00       247\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       972\n",
      "   macro avg       1.00      1.00      1.00       972\n",
      "weighted avg       1.00      1.00      1.00       972\n",
      " samples avg       0.44      0.44      0.44       972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Accuracy_score, Loss, Zero_one_loss, Hamming_loss, ML_confusion_matrix = classification_report_ensemble_voting_classifier(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report : \")\n",
    "print(\"Accuracy_score:\", Accuracy_score,'%')\n",
    "print(\"Loss:\", Loss,'%')\n",
    "print(\"Zero_one_loss:\", Zero_one_loss,'%')\n",
    "print(\"Hamming_loss:\", Hamming_loss,'%')\n",
    "print(\"ML_confusion_matrix:\\n\", ML_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builMultiLabelModels(X_train, X_test, y_train, y_test, classifierModel):\n",
    "    \n",
    "    multiLabelModel = MultiOutputClassifier(classifierModel, n_jobs=2)\n",
    "    \n",
    "    classifierModel = multiLabelModel.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifierModel.predict(X_test)\n",
    "    \n",
    "    # print(y_pred)\n",
    "    \n",
    "    print(\"Accuracy_score:\", round((accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "    doc.add_paragraph(f\"Accuracy_score : {round((accuracy_score(y_test, y_pred))*100,2)} %\")\n",
    "    \n",
    "    print(\"Loss:\", round((1-accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "    doc.add_paragraph(f\"Loss : {round((1-accuracy_score(y_test, y_pred))*100,2)} %\")\n",
    "    \n",
    "    print(\"Hamming_loss:\", round((hamming_loss(y_test, y_pred))*100,2),'%')\n",
    "    doc.add_paragraph(f\"Hamming_loss : {round((hamming_loss(y_test, y_pred))*100,2)} %\")\n",
    "    \n",
    "    print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))\n",
    "    doc.add_paragraph(f\"Classification_report : \\n{metrics.classification_report(y_test, y_pred)} \")\n",
    "\n",
    "#     print(\"confusion_matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return classifierModel, {'Accuracy': round((accuracy_score(y_test, y_pred))*100,2), \n",
    "                             'Loss': round((1-accuracy_score(y_test, y_pred))*100,2), \n",
    "                             'Hamming_loss': round((hamming_loss(y_test, y_pred))*100,2)\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : lr_Classifier\n",
      "Accuracy_score: 74.39 %\n",
      "Loss: 25.61 %\n",
      "Hamming_loss: 7.03 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.73       350\n",
      "           1       0.59      0.42      0.49       201\n",
      "           2       0.89      0.89      0.89       144\n",
      "           3       1.00      0.93      0.97        30\n",
      "           4       0.87      0.89      0.88       247\n",
      "\n",
      "   micro avg       0.80      0.72      0.76       972\n",
      "   macro avg       0.83      0.76      0.79       972\n",
      "weighted avg       0.79      0.72      0.75       972\n",
      " samples avg       0.32      0.32      0.31       972\n",
      "\n",
      "File saved : MultiLabelModel_lr_Classifier.pkl\n",
      "data : {'Accuracy': 74.39, 'Loss': 25.61, 'Hamming_loss': 7.03, 'Model_name': 'lr_Classifier', 'Filename': 'MultiLabelModel_lr_Classifier.pkl'}\n",
      "Model : knn_Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 82.74 %\n",
      "Loss: 17.26 %\n",
      "Hamming_loss: 4.63 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       350\n",
      "           1       0.82      0.85      0.83       201\n",
      "           2       0.89      0.90      0.89       144\n",
      "           3       1.00      0.37      0.54        30\n",
      "           4       0.91      0.98      0.94       247\n",
      "\n",
      "   micro avg       0.86      0.84      0.85       972\n",
      "   macro avg       0.89      0.77      0.80       972\n",
      "weighted avg       0.86      0.84      0.84       972\n",
      " samples avg       0.36      0.36      0.35       972\n",
      "\n",
      "File saved : MultiLabelModel_knn_Classifier.pkl\n",
      "data : {'Accuracy': 82.74, 'Loss': 17.26, 'Hamming_loss': 4.63, 'Model_name': 'knn_Classifier', 'Filename': 'MultiLabelModel_knn_Classifier.pkl'}\n",
      "Model : nb_Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 62.41 %\n",
      "Loss: 37.59 %\n",
      "Hamming_loss: 15.65 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.73      0.63       350\n",
      "           1       0.43      0.84      0.57       201\n",
      "           2       0.48      0.99      0.65       144\n",
      "           3       0.13      0.90      0.23        30\n",
      "           4       0.71      1.00      0.83       247\n",
      "\n",
      "   micro avg       0.49      0.87      0.63       972\n",
      "   macro avg       0.46      0.89      0.58       972\n",
      "weighted avg       0.54      0.87      0.66       972\n",
      " samples avg       0.22      0.36      0.25       972\n",
      "\n",
      "File saved : MultiLabelModel_nb_Classifier.pkl\n",
      "data : {'Accuracy': 62.41, 'Loss': 37.59, 'Hamming_loss': 15.65, 'Model_name': 'nb_Classifier', 'Filename': 'MultiLabelModel_nb_Classifier.pkl'}\n",
      "Model : svm_Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 60.05 %\n",
      "Loss: 39.95 %\n",
      "Hamming_loss: 13.6 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.10      0.18       350\n",
      "           1       0.92      0.06      0.11       201\n",
      "           2       1.00      0.10      0.19       144\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       1.00      0.20      0.33       247\n",
      "\n",
      "   micro avg       0.98      0.11      0.20       972\n",
      "   macro avg       0.78      0.09      0.16       972\n",
      "weighted avg       0.94      0.11      0.20       972\n",
      " samples avg       0.06      0.05      0.05       972\n",
      "\n",
      "File saved : MultiLabelModel_svm_Classifier.pkl\n",
      "data : {'Accuracy': 60.05, 'Loss': 39.95, 'Hamming_loss': 13.6, 'Model_name': 'svm_Classifier', 'Filename': 'MultiLabelModel_svm_Classifier.pkl'}\n",
      "Model : dt_Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 95.74 %\n",
      "Loss: 4.26 %\n",
      "Hamming_loss: 0.91 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       350\n",
      "           1       0.95      0.92      0.93       201\n",
      "           2       0.99      1.00      0.99       144\n",
      "           3       0.84      0.90      0.87        30\n",
      "           4       1.00      1.00      1.00       247\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       972\n",
      "   macro avg       0.95      0.96      0.95       972\n",
      "weighted avg       0.97      0.97      0.97       972\n",
      " samples avg       0.43      0.42      0.42       972\n",
      "\n",
      "File saved : MultiLabelModel_dt_Classifier.pkl\n",
      "data : {'Accuracy': 95.74, 'Loss': 4.26, 'Hamming_loss': 0.91, 'Model_name': 'dt_Classifier', 'Filename': 'MultiLabelModel_dt_Classifier.pkl'}\n",
      "Model : rf_Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 96.38 %\n",
      "Loss: 3.62 %\n",
      "Hamming_loss: 0.74 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       350\n",
      "           1       0.96      0.96      0.96       201\n",
      "           2       1.00      0.98      0.99       144\n",
      "           3       1.00      0.90      0.95        30\n",
      "           4       1.00      1.00      1.00       247\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       972\n",
      "   macro avg       0.98      0.96      0.97       972\n",
      "weighted avg       0.98      0.98      0.98       972\n",
      " samples avg       0.43      0.43      0.43       972\n",
      "\n",
      "File saved : MultiLabelModel_rf_Classifier.pkl\n",
      "data : {'Accuracy': 96.38, 'Loss': 3.62, 'Hamming_loss': 0.74, 'Model_name': 'rf_Classifier', 'Filename': 'MultiLabelModel_rf_Classifier.pkl'}\n",
      "Model : gb_Classifier"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy_score: 96.53 %\n",
      "Loss: 3.47 %\n",
      "Hamming_loss: 0.71 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       350\n",
      "           1       0.95      0.97      0.96       201\n",
      "           2       0.99      1.00      0.99       144\n",
      "           3       1.00      0.90      0.95        30\n",
      "           4       1.00      1.00      1.00       247\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       972\n",
      "   macro avg       0.98      0.97      0.97       972\n",
      "weighted avg       0.97      0.98      0.98       972\n",
      " samples avg       0.43      0.43      0.43       972\n",
      "\n",
      "File saved : MultiLabelModel_gb_Classifier.pkl\n",
      "data : {'Accuracy': 96.53, 'Loss': 3.47, 'Hamming_loss': 0.71, 'Model_name': 'gb_Classifier', 'Filename': 'MultiLabelModel_gb_Classifier.pkl'}\n",
      "Model : ab_Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 95.82 %\n",
      "Loss: 4.18 %\n",
      "Hamming_loss: 0.88 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       350\n",
      "           1       0.94      0.94      0.94       201\n",
      "           2       0.99      1.00      1.00       144\n",
      "           3       0.94      0.97      0.95        30\n",
      "           4       1.00      1.00      1.00       247\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       972\n",
      "   macro avg       0.96      0.97      0.97       972\n",
      "weighted avg       0.97      0.97      0.97       972\n",
      " samples avg       0.43      0.42      0.42       972\n",
      "\n",
      "File saved : MultiLabelModel_ab_Classifier.pkl\n",
      "data : {'Accuracy': 95.82, 'Loss': 4.18, 'Hamming_loss': 0.88, 'Model_name': 'ab_Classifier', 'Filename': 'MultiLabelModel_ab_Classifier.pkl'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.39</td>\n",
       "      <td>MultiLabelModel_lr_Classifier.pkl</td>\n",
       "      <td>7.03</td>\n",
       "      <td>25.61</td>\n",
       "      <td>lr_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.74</td>\n",
       "      <td>MultiLabelModel_knn_Classifier.pkl</td>\n",
       "      <td>4.63</td>\n",
       "      <td>17.26</td>\n",
       "      <td>knn_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.41</td>\n",
       "      <td>MultiLabelModel_nb_Classifier.pkl</td>\n",
       "      <td>15.65</td>\n",
       "      <td>37.59</td>\n",
       "      <td>nb_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.05</td>\n",
       "      <td>MultiLabelModel_svm_Classifier.pkl</td>\n",
       "      <td>13.60</td>\n",
       "      <td>39.95</td>\n",
       "      <td>svm_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.74</td>\n",
       "      <td>MultiLabelModel_dt_Classifier.pkl</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4.26</td>\n",
       "      <td>dt_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96.38</td>\n",
       "      <td>MultiLabelModel_rf_Classifier.pkl</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3.62</td>\n",
       "      <td>rf_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96.53</td>\n",
       "      <td>MultiLabelModel_gb_Classifier.pkl</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.47</td>\n",
       "      <td>gb_Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95.82</td>\n",
       "      <td>MultiLabelModel_ab_Classifier.pkl</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4.18</td>\n",
       "      <td>ab_Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy                            Filename  Hamming_loss   Loss  \\\n",
       "0     74.39   MultiLabelModel_lr_Classifier.pkl          7.03  25.61   \n",
       "1     82.74  MultiLabelModel_knn_Classifier.pkl          4.63  17.26   \n",
       "2     62.41   MultiLabelModel_nb_Classifier.pkl         15.65  37.59   \n",
       "3     60.05  MultiLabelModel_svm_Classifier.pkl         13.60  39.95   \n",
       "4     95.74   MultiLabelModel_dt_Classifier.pkl          0.91   4.26   \n",
       "5     96.38   MultiLabelModel_rf_Classifier.pkl          0.74   3.62   \n",
       "6     96.53   MultiLabelModel_gb_Classifier.pkl          0.71   3.47   \n",
       "7     95.82   MultiLabelModel_ab_Classifier.pkl          0.88   4.18   \n",
       "\n",
       "       Model_name  \n",
       "0   lr_Classifier  \n",
       "1  knn_Classifier  \n",
       "2   nb_Classifier  \n",
       "3  svm_Classifier  \n",
       "4   dt_Classifier  \n",
       "5   rf_Classifier  \n",
       "6   gb_Classifier  \n",
       "7   ab_Classifier  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc = docx.Document()\n",
    "fname_date = datetime.datetime.now()  \n",
    "doc.add_heading(f'Classification Report {fname_date}', 0)\n",
    "if not os.path.exists(\"images\"): os.mkdir(\"images\")\n",
    "if not os.path.exists(\"docs\"): os.mkdir(\"docs\")\n",
    "\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for cls in range(len(classifiers)):\n",
    "    print(f'Model : {model_name[cls]}')\n",
    "    doc.add_heading(f\"Model : {model_name[cls]}\", 2)\n",
    "    \n",
    "    model, data = builMultiLabelModels(X_train, X_test, y_train, y_test, classifiers[cls])\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = f'MultiLabelModel_{model_name[cls]}'\n",
    "    filename = re.sub('\\W+','_', filename )+'.pkl'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    print(f'File saved : {filename}')\n",
    "    doc.add_paragraph(f\"File saved : {filename}\")\n",
    "\n",
    "    data['Model_name'] = model_name[cls]\n",
    "    data['Filename'] = filename\n",
    "\n",
    "    print(f'data : {data}')\n",
    "    doc.add_paragraph(f\"data : {data}\")\n",
    "\n",
    "    result_df = result_df.append(data, ignore_index=True)\n",
    "\n",
    "fname_date = ''.join(e for e in str(fname_date) if e.isalnum())\n",
    "doc.save(f\"docs/Classification_Report_MultiLabel_with_all_features_{fname_date}.docx\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Hamming_loss</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_Classifier</td>\n",
       "      <td>74.39</td>\n",
       "      <td>25.61</td>\n",
       "      <td>7.03</td>\n",
       "      <td>MultiLabelModel_lr_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn_Classifier</td>\n",
       "      <td>82.74</td>\n",
       "      <td>17.26</td>\n",
       "      <td>4.63</td>\n",
       "      <td>MultiLabelModel_knn_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb_Classifier</td>\n",
       "      <td>62.41</td>\n",
       "      <td>37.59</td>\n",
       "      <td>15.65</td>\n",
       "      <td>MultiLabelModel_nb_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm_Classifier</td>\n",
       "      <td>60.05</td>\n",
       "      <td>39.95</td>\n",
       "      <td>13.60</td>\n",
       "      <td>MultiLabelModel_svm_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt_Classifier</td>\n",
       "      <td>95.74</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.91</td>\n",
       "      <td>MultiLabelModel_dt_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf_Classifier</td>\n",
       "      <td>96.38</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.74</td>\n",
       "      <td>MultiLabelModel_rf_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gb_Classifier</td>\n",
       "      <td>96.53</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.71</td>\n",
       "      <td>MultiLabelModel_gb_Classifier.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ab_Classifier</td>\n",
       "      <td>95.82</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.88</td>\n",
       "      <td>MultiLabelModel_ab_Classifier.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model_name  Accuracy   Loss  Hamming_loss  \\\n",
       "0   lr_Classifier     74.39  25.61          7.03   \n",
       "1  knn_Classifier     82.74  17.26          4.63   \n",
       "2   nb_Classifier     62.41  37.59         15.65   \n",
       "3  svm_Classifier     60.05  39.95         13.60   \n",
       "4   dt_Classifier     95.74   4.26          0.91   \n",
       "5   rf_Classifier     96.38   3.62          0.74   \n",
       "6   gb_Classifier     96.53   3.47          0.71   \n",
       "7   ab_Classifier     95.82   4.18          0.88   \n",
       "\n",
       "                             Filename  \n",
       "0   MultiLabelModel_lr_Classifier.pkl  \n",
       "1  MultiLabelModel_knn_Classifier.pkl  \n",
       "2   MultiLabelModel_nb_Classifier.pkl  \n",
       "3  MultiLabelModel_svm_Classifier.pkl  \n",
       "4   MultiLabelModel_dt_Classifier.pkl  \n",
       "5   MultiLabelModel_rf_Classifier.pkl  \n",
       "6   MultiLabelModel_gb_Classifier.pkl  \n",
       "7   MultiLabelModel_ab_Classifier.pkl  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df1 = result_df[['Model_name', 'Accuracy', 'Loss', 'Hamming_loss', 'Filename']]\n",
    "result_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df1.to_csv('part6//MultiLabelModel_result_with_all_features_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
