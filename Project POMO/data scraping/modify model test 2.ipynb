{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.pandas.set_option('display.max_columns',None)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "import docx\n",
    "from docx.shared import Inches\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>tempC_7to8</th>\n",
       "      <th>tempC_1to2</th>\n",
       "      <th>tempC_6to7</th>\n",
       "      <th>tempC_avg(0C)</th>\n",
       "      <th>Relative humidity_7to8</th>\n",
       "      <th>Relative humidity_1to2</th>\n",
       "      <th>Relative humidity_6to7</th>\n",
       "      <th>Relative humidity_avg(%)</th>\n",
       "      <th>windspeedKmph_7to8</th>\n",
       "      <th>windspeedKmph_1to2</th>\n",
       "      <th>windspeedKmph_6to7</th>\n",
       "      <th>windspeedKmph_avg(Km/h)</th>\n",
       "      <th>pressureMB_7to8</th>\n",
       "      <th>pressureMB_1to2</th>\n",
       "      <th>pressureMB_6to7</th>\n",
       "      <th>pressureMB_avg</th>\n",
       "      <th>precipMM_7to8</th>\n",
       "      <th>precipMM_1to2</th>\n",
       "      <th>precipMM_6to7</th>\n",
       "      <th>precipMM_avg(mm)</th>\n",
       "      <th>weatherDesc_7to8</th>\n",
       "      <th>weatherDesc_1to2</th>\n",
       "      <th>weatherDesc_6to7</th>\n",
       "      <th>weatherDesc</th>\n",
       "      <th>Sunshine Hours</th>\n",
       "      <th>%_soil_moisure</th>\n",
       "      <th>soil_pH</th>\n",
       "      <th>water_pH</th>\n",
       "      <th>water_TDS_mgpl</th>\n",
       "      <th>Label (Disease Yes/No)</th>\n",
       "      <th>Type of Disease (Bacterial Blight/Telya)</th>\n",
       "      <th>Anthracnose</th>\n",
       "      <th>Fruit Spot/ Rot</th>\n",
       "      <th>Fusarium Wilt</th>\n",
       "      <th>Fruit Borer / Blight Blora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1015</td>\n",
       "      <td>1012</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>45</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>62</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1015</td>\n",
       "      <td>1013</td>\n",
       "      <td>1015</td>\n",
       "      <td>1014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>45</td>\n",
       "      <td>6.77</td>\n",
       "      <td>7.66</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>61</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1017</td>\n",
       "      <td>1014</td>\n",
       "      <td>1015</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>41</td>\n",
       "      <td>6.76</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1016</td>\n",
       "      <td>1012</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>43</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.43</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1013</td>\n",
       "      <td>1010</td>\n",
       "      <td>1012</td>\n",
       "      <td>1011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>44</td>\n",
       "      <td>6.53</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation  date  month  year  tempC_7to8  tempC_1to2  tempC_6to7  \\\n",
       "0  2010-01-01     1      1  2010          20          30          20   \n",
       "1  2010-01-02     2      1  2010          23          29          23   \n",
       "2  2010-01-03     3      1  2010          24          27          21   \n",
       "3  2010-01-04     4      1  2010          23          29          20   \n",
       "4  2010-01-05     5      1  2010          22          30          21   \n",
       "\n",
       "   tempC_avg(0C)  Relative humidity_7to8  Relative humidity_1to2  \\\n",
       "0             23                      42                      33   \n",
       "1             25                      49                      40   \n",
       "2             24                      61                      50   \n",
       "3             24                      57                      30   \n",
       "4             24                      48                      34   \n",
       "\n",
       "   Relative humidity_6to7  Relative humidity_avg(%)  windspeedKmph_7to8  \\\n",
       "0                      59                        44                   9   \n",
       "1                      62                        50                   9   \n",
       "2                      78                        63                   4   \n",
       "3                      52                        46                   5   \n",
       "4                      54                        45                   6   \n",
       "\n",
       "   windspeedKmph_1to2  windspeedKmph_6to7  windspeedKmph_avg(Km/h)  \\\n",
       "0                   2                   4                        5   \n",
       "1                   3                   3                        5   \n",
       "2                   8                   6                        6   \n",
       "3                   7                   6                        6   \n",
       "4                   2                   4                        4   \n",
       "\n",
       "   pressureMB_7to8  pressureMB_1to2  pressureMB_6to7  pressureMB_avg  \\\n",
       "0             1015             1012             1013            1013   \n",
       "1             1015             1013             1015            1014   \n",
       "2             1017             1014             1015            1015   \n",
       "3             1016             1012             1013            1013   \n",
       "4             1013             1010             1012            1011   \n",
       "\n",
       "   precipMM_7to8  precipMM_1to2  precipMM_6to7  precipMM_avg(mm)  \\\n",
       "0            0.0            0.0            0.0               0.0   \n",
       "1            0.0            0.0            0.0               0.0   \n",
       "2            0.0            0.0            0.0               0.0   \n",
       "3            0.0            0.0            0.0               0.0   \n",
       "4            0.0            0.0            0.0               0.0   \n",
       "\n",
       "   weatherDesc_7to8  weatherDesc_1to2  weatherDesc_6to7  weatherDesc  \\\n",
       "0                 5                 5                 5            5   \n",
       "1                 5                 4                 4            4   \n",
       "2                 4                 4                 4            4   \n",
       "3                 5                 5                 5            5   \n",
       "4                 5                 5                 5            5   \n",
       "\n",
       "   Sunshine Hours  %_soil_moisure  soil_pH  water_pH  water_TDS_mgpl  \\\n",
       "0             9.8              45     6.91      7.18          1709.0   \n",
       "1             9.8              45     6.77      7.66          1707.0   \n",
       "2             9.8              41     6.76      7.44          1707.0   \n",
       "3             9.8              43     7.10      7.43          1708.0   \n",
       "4             9.8              44     6.53      8.05          1709.0   \n",
       "\n",
       "   Label (Disease Yes/No)  Type of Disease (Bacterial Blight/Telya)  \\\n",
       "0                       0                                         0   \n",
       "1                       1                                         1   \n",
       "2                       0                                         0   \n",
       "3                       0                                         0   \n",
       "4                       0                                         0   \n",
       "\n",
       "   Anthracnose  Fruit Spot/ Rot  Fusarium Wilt  Fruit Borer / Blight Blora  \n",
       "0            0                0              0                           0  \n",
       "1            1                0              0                           0  \n",
       "2            0                0              0                           0  \n",
       "3            0                0              0                           0  \n",
       "4            0                0              0                           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'part6\\Historical Weather Data 2010-2021_preprocessed_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['observation', 'date', 'month', 'year', 'tempC_7to8', 'tempC_1to2', 'tempC_6to7', 'tempC_avg(0C)', 'Relative humidity_7to8', 'Relative humidity_1to2', 'Relative humidity_6to7', 'Relative humidity_avg(%)', 'windspeedKmph_7to8', 'windspeedKmph_1to2', 'windspeedKmph_6to7', 'windspeedKmph_avg(Km/h)', 'pressureMB_7to8', 'pressureMB_1to2', 'pressureMB_6to7', 'pressureMB_avg', 'precipMM_7to8', 'precipMM_1to2', 'precipMM_6to7', 'precipMM_avg(mm)', 'weatherDesc_7to8', 'weatherDesc_1to2', 'weatherDesc_6to7', 'weatherDesc', 'Sunshine Hours', '%_soil_moisure', 'soil_pH', 'water_pH', 'water_TDS_mgpl', 'Label (Disease Yes/No)', 'Type of Disease (Bacterial Blight/Telya)', 'Anthracnose', 'Fruit Spot/ Rot', 'Fusarium Wilt', 'Fruit Borer / Blight Blora']\n"
     ]
    }
   ],
   "source": [
    "# columns name \n",
    "\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4227 entries, 0 to 4226\n",
      "Data columns (total 39 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   observation                               4227 non-null   object \n",
      " 1   date                                      4227 non-null   int64  \n",
      " 2   month                                     4227 non-null   int64  \n",
      " 3   year                                      4227 non-null   int64  \n",
      " 4   tempC_7to8                                4227 non-null   int64  \n",
      " 5   tempC_1to2                                4227 non-null   int64  \n",
      " 6   tempC_6to7                                4227 non-null   int64  \n",
      " 7   tempC_avg(0C)                             4227 non-null   int64  \n",
      " 8   Relative humidity_7to8                    4227 non-null   int64  \n",
      " 9   Relative humidity_1to2                    4227 non-null   int64  \n",
      " 10  Relative humidity_6to7                    4227 non-null   int64  \n",
      " 11  Relative humidity_avg(%)                  4227 non-null   int64  \n",
      " 12  windspeedKmph_7to8                        4227 non-null   int64  \n",
      " 13  windspeedKmph_1to2                        4227 non-null   int64  \n",
      " 14  windspeedKmph_6to7                        4227 non-null   int64  \n",
      " 15  windspeedKmph_avg(Km/h)                   4227 non-null   int64  \n",
      " 16  pressureMB_7to8                           4227 non-null   int64  \n",
      " 17  pressureMB_1to2                           4227 non-null   int64  \n",
      " 18  pressureMB_6to7                           4227 non-null   int64  \n",
      " 19  pressureMB_avg                            4227 non-null   int64  \n",
      " 20  precipMM_7to8                             4227 non-null   float64\n",
      " 21  precipMM_1to2                             4227 non-null   float64\n",
      " 22  precipMM_6to7                             4227 non-null   float64\n",
      " 23  precipMM_avg(mm)                          4227 non-null   float64\n",
      " 24  weatherDesc_7to8                          4227 non-null   int64  \n",
      " 25  weatherDesc_1to2                          4227 non-null   int64  \n",
      " 26  weatherDesc_6to7                          4227 non-null   int64  \n",
      " 27  weatherDesc                               4227 non-null   int64  \n",
      " 28  Sunshine Hours                            4227 non-null   float64\n",
      " 29  %_soil_moisure                            4227 non-null   int64  \n",
      " 30  soil_pH                                   4227 non-null   float64\n",
      " 31  water_pH                                  4227 non-null   float64\n",
      " 32  water_TDS_mgpl                            4227 non-null   float64\n",
      " 33  Label (Disease Yes/No)                    4227 non-null   int64  \n",
      " 34  Type of Disease (Bacterial Blight/Telya)  4227 non-null   int64  \n",
      " 35  Anthracnose                               4227 non-null   int64  \n",
      " 36  Fruit Spot/ Rot                           4227 non-null   int64  \n",
      " 37  Fusarium Wilt                             4227 non-null   int64  \n",
      " 38  Fruit Borer / Blight Blora                4227 non-null   int64  \n",
      "dtypes: float64(8), int64(30), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# dataset info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_Classifier = LogisticRegression(max_iter=1000, random_state=3757)  \n",
    "knn_Classifier = KNeighborsClassifier(n_jobs=-1, n_neighbors=5, p=2, weights='uniform')  \n",
    "nb_Classifier = GaussianNB(priors=None, var_smoothing=1e-09)\n",
    "svm_Classifier = SVC(gamma='auto')\n",
    "dt_Classifier = DecisionTreeClassifier(random_state=3757)\n",
    "rf_Classifier = RandomForestClassifier(n_jobs=-1, random_state=3757)\n",
    "gb_Classifier = GradientBoostingClassifier(random_state=3757)\n",
    "ab_Classifier = AdaBoostClassifier(random_state=3757)\n",
    "\n",
    "classifiers = [lr_Classifier, knn_Classifier, nb_Classifier, svm_Classifier, dt_Classifier, \n",
    "               rf_Classifier, gb_Classifier, ab_Classifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempC_avg(0C)', 'Relative humidity_avg(%)', 'windspeedKmph_avg(Km/h)', 'pressureMB_avg', \n",
    "        'precipMM_avg(mm)', 'weatherDesc', 'Sunshine Hours', '%_soil_moisure']]\n",
    "Y = df[['Type of Disease (Bacterial Blight/Telya)', 'Anthracnose', 'Fruit Spot/ Rot', \n",
    "        'Fusarium Wilt', 'Fruit Borer / Blight Blora']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def builMultiLabelModels(X_train, X_test, y_train, y_test, classifierModel):\n",
    "    \n",
    "#     multiLabelModel = MultiOutputClassifier(classifierModel, n_jobs=2)\n",
    "    \n",
    "#     classifierModel = multiLabelModel.fit(X_train, y_train)\n",
    "    \n",
    "#     y_pred = classifierModel.predict(X_test)\n",
    "    \n",
    "#     print(\"Accuracy_score:\", round((accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "#     print(\"Loss:\", round((1-accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "#     print(\"Hamming_loss:\", round((hamming_loss(y_test, y_pred))*100,2),'%')\n",
    "#     print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "#     return classifierModel, {'Accuracy': round((accuracy_score(y_test, y_pred))*100,2), \n",
    "#                              'Loss': round((1-accuracy_score(y_test, y_pred))*100,2), \n",
    "#                              'Hamming_loss': round((hamming_loss(y_test, y_pred))*100,2)\n",
    "#                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_MultiLabelModelResult(classifiers):\n",
    "    \n",
    "    \n",
    "#     fname_date = datetime.datetime.now()  \n",
    "    \n",
    "#     os.makedirs(\"images\", exist_ok = True)\n",
    "#     os.makedirs(\"docs\", exist_ok = True)\n",
    "\n",
    "#     result_df = pd.DataFrame()\n",
    "\n",
    "#     for classifier in range(len(classifiers)):\n",
    "#         print(f'Model : {type(classifier).__name__}')\n",
    "\n",
    "#         model, data = builMultiLabelModels(X_train, X_test, y_train, y_test, classifiers[cls])\n",
    "\n",
    "#         # save the model to disk\n",
    "#         filename = f'MultiLabelModel_{model_name[cls]}'\n",
    "#         filename = re.sub('\\W+','_', filename )+'.pkl'\n",
    "#         pickle.dump(model, open(filename, 'wb'))\n",
    "#         print(f'File saved : {filename}')\n",
    "\n",
    "#         data['Model_name'] = model_name[cls]\n",
    "#         data['Filename'] = filename\n",
    "\n",
    "#         print(f'data : {data}')\n",
    "\n",
    "#         result_df = result_df.append(data, ignore_index=True)\n",
    "\n",
    "#     fname_date = ''.join(e for e in str(fname_date) if e.isalnum())\n",
    "\n",
    "    \n",
    "#     result_df1 = result_df[['Model_name', 'Accuracy', 'Loss', 'Hamming_loss', 'Filename']]\n",
    "#     result_df1.to_csv(f'part6//MultiLabelModel_result_{fname_date}.csv', index=False)\n",
    "    \n",
    "#     return result_df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_ensemble_voting_classifier(X_train, y_train, classifiers):\n",
    "    \n",
    "# #     selecting top 3 models\n",
    "#     models_df = get_MultiLabelModelResult(classifiers)\n",
    "    \n",
    "#     models_list = list(models_df.sort_values(by = ['Accuracy'], ascending = False)[0:3]['Filename'].values)\n",
    "    \n",
    "# #     get model prediction results\n",
    "#     output_list = []\n",
    "#     for path in models_list:\n",
    "#         model = pickle.load(open(path, 'rb')) \n",
    "#         pred = model.predict(X_test)\n",
    "#         output_list.append(pred)\n",
    "\n",
    "# #     get predicted values (from votting)\n",
    "#     and_of_pred = (output_list[0] & output_list[1] & output_list[2])\n",
    "#     or_of_pred = (output_list[0] | output_list[1] | output_list[2])\n",
    "#     y_pred_new = np.nan_to_num(and_of_pred // or_of_pred)\n",
    "    \n",
    "#     print(\"Accuracy_score:\", round((accuracy_score(y_test, y_pred_new))*100,2),'%')\n",
    "#     print(\"Loss:\", round((1-accuracy_score(y_test, y_pred_new))*100,2),'%')\n",
    "#     print(\"Hamming_loss:\", round((hamming_loss(y_test, y_pred_new))*100,2),'%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_ensemble_voting_classifier(X_train, y_train, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from POMO_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : LogisticRegression\n",
      "Accuracy_score: 70.72 %\n",
      "Loss: 29.28 %\n",
      "Hamming_loss: 7.99 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.61      0.68       855\n",
      "           1       0.49      0.19      0.27       512\n",
      "           2       0.91      0.89      0.90       302\n",
      "           3       1.00      0.92      0.96        65\n",
      "           4       0.88      0.92      0.90       544\n",
      "\n",
      "   micro avg       0.81      0.63      0.71      2278\n",
      "   macro avg       0.81      0.70      0.74      2278\n",
      "weighted avg       0.76      0.63      0.68      2278\n",
      " samples avg       0.30      0.28      0.28      2278\n",
      "\n",
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_LogisticRegression.pkl\n",
      "data : {'Accuracy': 70.72, 'Loss': 29.28, 'Hamming_loss': 7.99, 'Model_name': 'LogisticRegression', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_LogisticRegression.pkl'}\n",
      "Model : KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 88.84 %\n",
      "Loss: 11.16 %\n",
      "Hamming_loss: 2.73 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       855\n",
      "           1       0.91      0.90      0.91       512\n",
      "           2       0.96      0.99      0.98       302\n",
      "           3       0.96      0.68      0.79        65\n",
      "           4       0.94      0.98      0.96       544\n",
      "\n",
      "   micro avg       0.93      0.89      0.91      2278\n",
      "   macro avg       0.94      0.87      0.90      2278\n",
      "weighted avg       0.93      0.89      0.91      2278\n",
      " samples avg       0.38      0.38      0.38      2278\n",
      "\n",
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_KNeighborsClassifier.pkl\n",
      "data : {'Accuracy': 88.84, 'Loss': 11.16, 'Hamming_loss': 2.73, 'Model_name': 'KNeighborsClassifier', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_KNeighborsClassifier.pkl'}\n",
      "Model : GaussianNB\n",
      "Accuracy_score: 62.41 %\n",
      "Loss: 37.59 %\n",
      "Hamming_loss: 14.13 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.69      0.61       855\n",
      "           1       0.46      0.83      0.59       512\n",
      "           2       0.52      0.98      0.68       302\n",
      "           3       0.24      1.00      0.38        65\n",
      "           4       0.68      0.98      0.80       544\n",
      "\n",
      "   micro avg       0.53      0.84      0.65      2278\n",
      "   macro avg       0.49      0.89      0.61      2278\n",
      "weighted avg       0.55      0.84      0.65      2278\n",
      " samples avg       0.21      0.34      0.25      2278\n",
      "\n",
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_GaussianNB.pkl\n",
      "data : {'Accuracy': 62.41, 'Loss': 37.59, 'Hamming_loss': 14.13, 'Model_name': 'GaussianNB', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_GaussianNB.pkl'}\n",
      "Model : SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 97.46 %\n",
      "Loss: 2.54 %\n",
      "Hamming_loss: 0.53 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       855\n",
      "           1       0.99      0.98      0.98       512\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      0.85      0.92        65\n",
      "           4       1.00      1.00      1.00       544\n",
      "\n",
      "   micro avg       0.99      0.97      0.98      2278\n",
      "   macro avg       1.00      0.95      0.97      2278\n",
      "weighted avg       0.99      0.97      0.98      2278\n",
      " samples avg       0.42      0.42      0.42      2278\n",
      "\n",
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_SVC.pkl\n",
      "data : {'Accuracy': 97.46, 'Loss': 2.54, 'Hamming_loss': 0.53, 'Model_name': 'SVC', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_SVC.pkl'}\n",
      "Model : DecisionTreeClassifier\n",
      "Accuracy_score: 100.0 %\n",
      "Loss: 0.0 %\n",
      "Hamming_loss: 0.0 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00       512\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00        65\n",
      "           4       1.00      1.00      1.00       544\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2278\n",
      "   macro avg       1.00      1.00      1.00      2278\n",
      "weighted avg       1.00      1.00      1.00      2278\n",
      " samples avg       0.44      0.44      0.44      2278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_DecisionTreeClassifier.pkl\n",
      "data : {'Accuracy': 100.0, 'Loss': 0.0, 'Hamming_loss': 0.0, 'Model_name': 'DecisionTreeClassifier', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_DecisionTreeClassifier.pkl'}\n",
      "Model : RandomForestClassifier\n",
      "Accuracy_score: 100.0 %\n",
      "Loss: 0.0 %\n",
      "Hamming_loss: 0.0 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00       512\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00        65\n",
      "           4       1.00      1.00      1.00       544\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2278\n",
      "   macro avg       1.00      1.00      1.00      2278\n",
      "weighted avg       1.00      1.00      1.00      2278\n",
      " samples avg       0.44      0.44      0.44      2278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_RandomForestClassifier.pkl\n",
      "data : {'Accuracy': 100.0, 'Loss': 0.0, 'Hamming_loss': 0.0, 'Model_name': 'RandomForestClassifier', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_RandomForestClassifier.pkl'}\n",
      "Model : GradientBoostingClassifier\n",
      "Accuracy_score: 97.9 %\n",
      "Loss: 2.1 %\n",
      "Hamming_loss: 0.48 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       855\n",
      "           1       0.96      0.98      0.97       512\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00        65\n",
      "           4       1.00      1.00      1.00       544\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      2278\n",
      "   macro avg       0.99      0.99      0.99      2278\n",
      "weighted avg       0.98      0.99      0.98      2278\n",
      " samples avg       0.43      0.43      0.43      2278\n",
      "\n",
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_GradientBoostingClassifier.pkl\n",
      "data : {'Accuracy': 97.9, 'Loss': 2.1, 'Hamming_loss': 0.48, 'Model_name': 'GradientBoostingClassifier', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_GradientBoostingClassifier.pkl'}\n",
      "Model : AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 96.55 %\n",
      "Loss: 3.45 %\n",
      "Hamming_loss: 0.81 %\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       855\n",
      "           1       0.94      0.95      0.94       512\n",
      "           2       1.00      1.00      1.00       302\n",
      "           3       1.00      1.00      1.00        65\n",
      "           4       1.00      1.00      1.00       544\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      2278\n",
      "   macro avg       0.98      0.98      0.98      2278\n",
      "weighted avg       0.98      0.97      0.97      2278\n",
      " samples avg       0.42      0.42      0.42      2278\n",
      "\n",
      "File saved : D:\\test\\Basic_Python\\Project POMO\\data scraping\\Artifact\\2022-07-03-00-10-40\\Models\\MultiLabelModel_AdaBoostClassifier.pkl\n",
      "data : {'Accuracy': 96.55, 'Loss': 3.45, 'Hamming_loss': 0.81, 'Model_name': 'AdaBoostClassifier', 'Filename': 'D:\\\\test\\\\Basic_Python\\\\Project POMO\\\\data scraping\\\\Artifact\\\\2022-07-03-00-10-40\\\\Models\\\\MultiLabelModel_AdaBoostClassifier.pkl'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\munge\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "fit_ensemble_voting_classifier(X_train, y_train, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
