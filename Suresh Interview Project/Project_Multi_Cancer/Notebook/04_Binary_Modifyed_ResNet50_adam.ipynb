{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c03d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join('..', 'Dataset', 'Binary_class_dataset', 'train') # '/content/data/train'\n",
    "valid_data_path = os.path.join('..', 'Dataset', 'Binary_class_dataset', 'test') # '/content/data/test'\n",
    "\n",
    "train_data_agumentation = ImageDataGenerator(rescale = 1./255,\n",
    "                                             zoom_range = 0.1\n",
    "                                             )\n",
    "\n",
    "val_data_agumentation = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "# load training data\n",
    "train_data = train_data_agumentation.flow_from_directory(directory = train_data_path,\n",
    "                                                         target_size = (224,224),\n",
    "                                                         class_mode = 'categorical',\n",
    "                                                         batch_size = 32)\n",
    "\n",
    "val_data = val_data_agumentation.flow_from_directory(directory = valid_data_path,\n",
    "                                                     target_size = (224,224),\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints_modified_Binary_class_ResNet50_adam'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir,\n",
    "                                   \"model_epoch_{epoch:02d}_val_acc_{val_accuracy:.2f}_val_loss_{val_loss:.2f}.keras\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = checkpoint_filepath,\n",
    "                             monitor = 'val_loss',\n",
    "                             verbose = 0,\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False,\n",
    "                             mode = 'auto')\n",
    "\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "                      min_delta = 0,\n",
    "                      patience = 10,\n",
    "                      verbose = 0,\n",
    "                      mode = 'auto')\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor = \"val_loss\", \n",
    "                             factor = 0.1,\n",
    "                             patience = 10, \n",
    "                             verbose = 0, \n",
    "                             mode = \"auto\",\n",
    "                             min_delta = 0.0001, \n",
    "                             cooldown = 0,\n",
    "                             min_lr = 0.0)\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(checkpoint_dir, 'training.log'))\n",
    "\n",
    "callbacks_list = [checkpoint, reduceLR, csv_logger] #, early\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2741f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [224, 224]\n",
    "num_classes = len(glob.glob(train_data_path+'/*'))\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = ResNet50(input_shape = image_size + [3],\n",
    "              weights = 'imagenet',\n",
    "              include_top = False)\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "# Add Custom Classification Layers\n",
    "# - add custom layers on top of the VGG16 base model. \n",
    "# These layers will be responsible for classifying lymphoma \n",
    "# types based on the features extracted by the base model.\n",
    "x = Flatten()(model.output)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# model.layers.trainable = False\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# for layer in model.layers[-4:]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs = model.input, outputs = output_layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "adam = Adam(learning_rate = 0.001, \n",
    "            beta_1 = 0.9,\n",
    "            beta_2 = 0.999,\n",
    "            epsilon = 1e-07)\n",
    "\n",
    "# compile the model with adam optimizer, categorical_croosentropy loss function\n",
    "model.compile(optimizer = adam,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc559105",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 5,\n",
    "                    validation_data = val_data,\n",
    "                    callbacks = callbacks_list)\n",
    "\n",
    "# steps_per_epoch=len(training_set),\n",
    "# validation_steps=len(test_set),\n",
    "\n",
    "# steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "# validation_data=validation_generator,\n",
    "# validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "\n",
    "# model.save('modified_ResNet50_adam_model_last_epoch.h5')\n",
    "# Save the trained model\n",
    "save_model_path = os.path.join(checkpoint_dir, 'modified_Binary_class_ResNet50_adam_model_last_epoch.h5')\n",
    "model.save(save_model_path)\n",
    "print(f\"Model saved as {save_model_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('Binary_class_modified_ResNet50_adam_model_accuracy_and_val_accuracy.png', dpi=200)\n",
    "plt.show()\n",
    " \n",
    "# loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig('Binary_class_modified_ResNet50_adam_model_loss_and_val_loss.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df99d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(train_data, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(val_data, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be244b",
   "metadata": {},
   "source": [
    "# Create Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1508c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d25e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Classification Report\n",
    "\n",
    "def evaluate_model(y_true, y_pred, class_names=None):\n",
    "    \"\"\"\n",
    "    This function evaluates the performance of a model and prints the confusion matrix, \n",
    "    accuracy score, classification report, and Cohen's kappa score. It also plots a heatmap of the confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        y_true (array-like): Ground truth (true labels)\n",
    "        y_pred (array-like): Predicted labels from the model\n",
    "        class_names (list): List of class names for better readability in the confusion matrix\n",
    "        \n",
    "    Returns:\n",
    "        None: Displays the evaluation metrics and heatmap.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Get classification report\n",
    "    class_report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    \n",
    "    # Calculate Cohen's kappa score\n",
    "    kappa_score = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"\\nAccuracy Score: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "    print(f\"Cohen's Kappa Score: {kappa_score:.4f}\")\n",
    "    \n",
    "    # Plot heatmap for confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix Heatmap')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_classification_report(model_path, test_data_dir):\n",
    "    # Step 1: Set up directories and parameters\n",
    "    # test_data_dir = 'data/train/'  # Path to the directory containing test images in folders 0, 1, 2\n",
    "\n",
    "    # Step 2: Load the trained model\n",
    "    model = load_model(model_path)  # Assuming you've saved the model as .h5\n",
    "\n",
    "    # Step 3: ImageDataGenerator for loading test images (no augmentation needed for testing)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values to [0, 1]\n",
    "\n",
    "    # Step 4: Load test data using flow_from_directory\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size = (224, 224),  # Same size as the input size for your model\n",
    "        batch_size = 32,  # Adjust according to your hardware\n",
    "        class_mode = 'categorical',  # For multi-class classification\n",
    "        shuffle = False  # Don't shuffle, we need to keep track of the order for y_true\n",
    "    )\n",
    "\n",
    "    # Step 5: Get true labels from the generator\n",
    "    y_true = test_generator.classes  # These are the true class labels\n",
    "\n",
    "    # Step 6: Predict using the model\n",
    "    y_pred_prob = model.predict(test_generator)  # Predict probabilities for each class\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Get the index of the max probability (class label)\n",
    "\n",
    "    # Step 7: Map predicted and true labels to class names\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "    # You can use the evaluation function from earlier for further analysis\n",
    "    evaluate_model(y_true, y_pred, class_names=class_labels)\n",
    "    \n",
    "# Call the function\n",
    "\n",
    "model_path = os.path.join(checkpoint_dir, 'modified_Binary_class_ResNet50_adam_model_last_epoch.h5')\n",
    "test_data_dir = os.path.join('..', 'Dataset', 'Binary_class_dataset', 'val')\n",
    "\n",
    "create_classification_report(model_path, test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba15bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccbc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
