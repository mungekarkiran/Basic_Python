{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ee913b",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "\n",
    "1. Custom CNN for Feature Extraction\n",
    "2. Texture Analysis using GLCM\n",
    "3. Saving Features to CSV\n",
    "4. Training an ANN Model\n",
    "5. Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc87fa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProjectWork\\Basic_Python\\Suresh Interview Project\\Project_Multi_Cancer\\venv_multican\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ace3a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Custom CNN Model for Feature Extraction\n",
    "def create_custom_cnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    model = models.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9fa017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Function to calculate GLCM properties\n",
    "def calculate_glcm_features(image, distances, angles):\n",
    "    properties = ['contrast', 'dissimilarity', 'homogeneity', \n",
    "                  'energy', 'correlation', 'ASM']\n",
    "    glcm = greycomatrix(image, \n",
    "                        distances = distances, \n",
    "                        angles = angles, \n",
    "                        symmetric = True, \n",
    "                        normed = True)\n",
    "    feature_vector = []\n",
    "    \n",
    "    for prop in properties:\n",
    "        prop_values = greycoprops(glcm, prop)\n",
    "        feature_vector.extend(prop_values.flatten())\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa78610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch CNN features, GLCM features, and save to CSV\n",
    "def extract_features_and_save(images, labels, cnn_model, output_csv, distances, angles):\n",
    "    feature_list = []\n",
    "    for i, image in enumerate(images):\n",
    "        print(f\"Processing image {i+1}/{len(images)}\")\n",
    "        \n",
    "        # CNN Features\n",
    "        image_expanded = np.expand_dims(image, axis=0)  # Expand dimensions for the CNN model\n",
    "        cnn_features = cnn_model.predict(image_expanded).flatten()\n",
    "        \n",
    "        # GLCM Features\n",
    "        image_gray = np.mean(image, axis=-1).astype(np.uint8)  # Convert to grayscale if needed\n",
    "        glcm_features = calculate_glcm_features(image_gray, distances, angles)\n",
    "        \n",
    "        # Combine CNN + GLCM features\n",
    "        combined_features = np.concatenate([cnn_features, glcm_features])\n",
    "        feature_list.append(np.concatenate([combined_features, [labels[i]]]))\n",
    "    \n",
    "    # Create a DataFrame and save to CSV\n",
    "    df = pd.DataFrame(feature_list)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb25aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create ANN model to train using extracted features\n",
    "def create_ann_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_dim=input_dim),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        #layers.Dense(1, activation='sigmoid')  # Adjust depending on the classification task (binary/multi-class)\n",
    "        layers.Dense(3, activation='softmax')  # Adjust depending on the classification task (binary/multi-class)\n",
    "    ])\n",
    "    \n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Adjust loss if multi-class\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Adjust loss if multi-class\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bef00a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Function to evaluate ANN model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    #y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Binary thresholding for binary classification\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)  # Get class with highest probability\n",
    "    y_true = np.argmax(y_test, axis=1)  # Convert one-hot to labels for classification report\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387d3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Load your dataset\n",
    "def load_dataset_from_directory(directory, img_size=(128, 128), batch_size=32):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        labels='inferred',\n",
    "        label_mode='int',  # 'int' for integer labels, change to 'categorical' if needed\n",
    "        image_size=img_size,  # Resize all images to the target size\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0e35cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1206 files belonging to 3 classes.\n",
      "Loaded 1206 images of shape (128, 128, 3)\n",
      "Loaded 1206 labels\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 64, 64, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 32, 32, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " global_average_pooling2d_5  (None, 128)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93248 (364.25 KB)\n",
      "Trainable params: 93248 (364.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "X_train.shape[1] : 422\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                27072     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29251 (114.26 KB)\n",
      "Trainable params: 29251 (114.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "55/55 [==============================] - 1s 6ms/step - loss: 0.8284 - accuracy: 0.6298 - val_loss: 0.5259 - val_accuracy: 0.7732\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8281 - val_loss: 0.3792 - val_accuracy: 0.8557\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8858 - val_loss: 0.3017 - val_accuracy: 0.8763\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9020 - val_loss: 0.3494 - val_accuracy: 0.8660\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9400 - val_loss: 0.2401 - val_accuracy: 0.8866\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.1844 - accuracy: 0.9354 - val_loss: 0.2745 - val_accuracy: 0.9175\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9619 - val_loss: 0.2074 - val_accuracy: 0.9278\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 0.2160 - val_accuracy: 0.9072\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9689 - val_loss: 0.1192 - val_accuracy: 0.9485\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9700 - val_loss: 0.3926 - val_accuracy: 0.8866\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9573 - val_loss: 0.1656 - val_accuracy: 0.9278\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0984 - accuracy: 0.9735 - val_loss: 0.1562 - val_accuracy: 0.9381\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9804 - val_loss: 0.1508 - val_accuracy: 0.9588\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.9850 - val_loss: 0.1038 - val_accuracy: 0.9794\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9908 - val_loss: 0.1583 - val_accuracy: 0.9485\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9850 - val_loss: 0.1028 - val_accuracy: 0.9794\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9977 - val_loss: 0.0839 - val_accuracy: 0.9691\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9794\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9794\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 0.0886 - val_accuracy: 0.9794\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9794\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9897\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9897\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9897\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9897\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9897\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9897\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9897\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9897\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9897\n",
      "Epoch 32/50\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "Epoch 33/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9897\n",
      "Epoch 34/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9794\n",
      "Epoch 35/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9897\n",
      "Epoch 36/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9794\n",
      "Epoch 37/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9897\n",
      "Epoch 38/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9794\n",
      "Epoch 39/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9794\n",
      "Epoch 40/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9794\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "Epoch 42/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9897\n",
      "Epoch 43/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "Epoch 44/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9897\n",
      "Epoch 45/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9794\n",
      "Epoch 46/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9897\n",
      "Epoch 47/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "Epoch 48/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9897\n",
      "Epoch 49/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9897\n",
      "Epoch 50/50\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9897\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        81\n",
      "           1       0.96      0.95      0.96        81\n",
      "           2       0.90      0.94      0.92        80\n",
      "\n",
      "    accuracy                           0.94       242\n",
      "   macro avg       0.94      0.94      0.94       242\n",
      "weighted avg       0.94      0.94      0.94       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 6: Load your dataset\n",
    "    # Load training data\n",
    "    train_directory = os.path.join('..', 'Dataset', 'data', 'train')\n",
    "    train_dataset = load_dataset_from_directory(train_directory)\n",
    "    \n",
    "    # Extract images and labels from the dataset\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for batch in train_dataset:\n",
    "        imgs, lbls = batch\n",
    "        images.append(imgs.numpy())  # Convert to numpy arrays\n",
    "        labels.append(lbls.numpy())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(f\"Loaded {images.shape[0]} images of shape {images.shape[1:]}\")\n",
    "    print(f\"Loaded {labels.shape[0]} labels\")\n",
    "\n",
    "    # Step 7: CNN Model for feature extraction\n",
    "    cnn_model = create_custom_cnn(input_shape=(128, 128, 3))\n",
    "    cnn_model.summary()\n",
    "    \n",
    "    # Step 8: GLCM parameters\n",
    "    distances = [1, 3, 5, 3, 1, 3, 5]\n",
    "    angles = [0, 0, 0, np.pi/4, np.pi/2, np.pi/2, np.pi/2]\n",
    "\n",
    "    # Step 9: Extract features and save to CSV\n",
    "    output_csv = 'features.csv'\n",
    "    #extract_features_and_save(images, labels, cnn_model, output_csv, distances, angles)\n",
    "\n",
    "    # Step 10: Load CSV and prepare for ANN training\n",
    "    data = pd.read_csv(output_csv)\n",
    "    X = data.iloc[:, :-1].values  # All columns except the last one (features)\n",
    "    y = data.iloc[:, -1].values  # Last column (labels)\n",
    "    \n",
    "    # One-hot encode labels for multi-class classification\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "    \n",
    "    # Preprocessing: Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split into train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(f\"X_train.shape[1] : {X_train.shape[1]}\")\n",
    "    \n",
    "    # Step 11: Create and train ANN\n",
    "    ann_model = create_ann_model(input_dim=X_train.shape[1])\n",
    "    ann_model.summary()\n",
    "    \n",
    "    ann_model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.1)\n",
    "\n",
    "    # Step 12: Evaluate the model\n",
    "    evaluate_model(ann_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77abb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
