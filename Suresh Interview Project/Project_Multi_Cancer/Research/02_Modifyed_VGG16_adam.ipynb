{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c03d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SURESH RAJPUROHIT\\OneDrive\\Desktop\\project_lymph\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8b08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3216 images belonging to 3 classes.\n",
      "Found 1584 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_path = os.path.join('..', 'Dataset', 'data', 'train') # '/content/data/train'\n",
    "valid_data_path = os.path.join('..', 'Dataset', 'data', 'test') # '/content/data/test'\n",
    "\n",
    "train_data_agumentation = ImageDataGenerator(rescale = 1./255\n",
    "                                            #  shear_range = 0.2,\n",
    "                                            #  zoom_range = 0.2,\n",
    "                                            #  horizontal_flip = True,\n",
    "                                            #  vertical_flip = True\n",
    "                                             )\n",
    "\n",
    "val_data_agumentation = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "# load training data\n",
    "train_data = train_data_agumentation.flow_from_directory(directory = train_data_path,\n",
    "                                                         target_size = (224,224),\n",
    "                                                         class_mode = 'categorical',\n",
    "                                                         batch_size = 64)\n",
    "\n",
    "val_data = val_data_agumentation.flow_from_directory(directory = valid_data_path,\n",
    "                                                     target_size = (224,224),\n",
    "                                                     class_mode = 'categorical',\n",
    "                                                     batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1f56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints_modified_vgg16_adam'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_filepath = os.path.join(checkpoint_dir,\n",
    "                                   \"model_epoch_{epoch:02d}_val_acc_{val_accuracy:.2f}_val_loss_{val_loss:.2f}.keras\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = checkpoint_filepath,\n",
    "                             monitor = 'val_loss',\n",
    "                             verbose = 0,\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False,\n",
    "                             mode = 'auto')\n",
    "\n",
    "early = EarlyStopping(monitor = 'val_loss',\n",
    "                      min_delta = 0,\n",
    "                      patience = 10,\n",
    "                      verbose = 0,\n",
    "                      mode = 'auto')\n",
    "\n",
    "reduceLR = ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                             factor=0.1,\n",
    "                             patience=10, \n",
    "                             verbose=0, \n",
    "                             mode=\"auto\",\n",
    "                             min_delta=0.0001, \n",
    "                             cooldown=0,\n",
    "                             min_lr=0.0)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "callbacks_list = [checkpoint, reduceLR, csv_logger] #, early\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2741f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SURESH RAJPUROHIT\\OneDrive\\Desktop\\project_lymph\\venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SURESH RAJPUROHIT\\OneDrive\\Desktop\\project_lymph\\venv\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              51382272  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68852035 (262.65 MB)\n",
      "Trainable params: 54137347 (206.52 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_size = [224, 224]\n",
    "num_classes = len(glob.glob(train_data_path+'/*'))\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = VGG16(input_shape = image_size + [3],\n",
    "              weights = 'imagenet',\n",
    "              include_top = False)\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "# Add Custom Classification Layers\n",
    "# - add custom layers on top of the VGG16 base model. \n",
    "# These layers will be responsible for classifying lymphoma \n",
    "# types based on the features extracted by the base model.\n",
    "x = Flatten()(model.output)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# model.layers.trainable = False\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# for layer in model.layers[-4:]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs = model.input, outputs = output_layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5998d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the hyperparameters\n",
    "adam = Adam(learning_rate = 0.001, \n",
    "            beta_1 = 0.9,\n",
    "            beta_2 = 0.999,\n",
    "            epsilon = 1e-07)\n",
    "\n",
    "# compile the model with adam optimizer, categorical_croosentropy loss function\n",
    "# model.compile(optimizer = 'adam',\n",
    "#               loss = 'categorical_crossentropy',\n",
    "#               metrics = ['accuracy'])\n",
    "model.compile(optimizer = adam,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc559105",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\SURESH RAJPUROHIT\\OneDrive\\Desktop\\project_lymph\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SURESH RAJPUROHIT\\OneDrive\\Desktop\\project_lymph\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 2/51 [>.............................] - ETA: 3:59 - loss: 3.7605 - accuracy: 0.3359"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    batch_size = 64,\n",
    "                    epochs = 100,\n",
    "                    validation_data = val_data,\n",
    "                    callbacks = callbacks_list)\n",
    "\n",
    "# steps_per_epoch=len(training_set),\n",
    "# validation_steps=len(test_set),\n",
    "\n",
    "model.save('modified_VGG16_adam_model_last_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('modified_VGG16_adam_model_accuracy_and_val_accuracy.png', dpi=200)\n",
    "plt.show()\n",
    " \n",
    "# loss\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.savefig('modified_VGG16_adam_model_loss_and_val_loss.png', dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df99d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(train_data, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(val_data, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
