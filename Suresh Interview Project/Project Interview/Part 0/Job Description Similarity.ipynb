{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Program to see how similar a resume is to a job description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=bkigzpBLN6o&t=11s\n",
    "# https://www.youtube.com/watch?v=2vD6EAjhl54\n",
    "# https://www.youtube.com/watch?v=m_CooIRM3UI&t=2s\n",
    "# !pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (resume and JD in .docx formate)\n",
    "resume = docx2txt.process(r'dataset/kiran resume.docx')\n",
    "\n",
    "# print resume\n",
    "print(resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_decription = docx2txt.process(r'dataset/JD1.docx')\n",
    "\n",
    "# print JD\n",
    "print(job_decription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of text\n",
    "text = [resume, job_decription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CounterVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text)\n",
    "\n",
    "# print count_matrix\n",
    "print(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# print similarity score\n",
    "similarity_score = cosine_similarity(count_matrix)\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the match percent.\n",
    "match_percent = round(similarity_score[1][0]*100,2)\n",
    "print(f\"Your reseme maches about {match_percent}% of the Job Description.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skills Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=8fVEMdHKmqM\n",
    "# https://github.com/OmkarPathak/pyresparser\n",
    "\n",
    "# !pip install python-docx\n",
    "# !pip install docx\n",
    "# !pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/topics/pyresparser\n",
    "# https://github.com/p-sachin/Resume_Screening_Project\n",
    "# https://github.com/DhavalThkkar/Resume_Parser\n",
    "# https://github.com/Akash1070/AI-Resume-Analyser-With-NLP\n",
    "# https://github.com/OmkarPathak/pyresparser\n",
    "# https://omkarpathak.in/pyresparser/\n",
    "# https://snyk.io/advisor/python/pyresparser\n",
    "\n",
    "# https://stackoverflow.com/questions/54334304/spacy-cant-find-model-en-core-web-sm-on-windows-10-and-python-3-5-3-anacon\n",
    "# https://github.com/explosion/spaCy/issues/4577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib's\n",
    "\n",
    "import os\n",
    "from pyresparser import ResumeParser\n",
    "from docx import Document\n",
    "\n",
    "import spacy\n",
    "spacy.load(\"en_core_web_sm\")\n",
    "# spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spaCy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_lg\n",
    "\n",
    "# # nltk\n",
    "# !python -m nltk.downloader words\n",
    "# !python -m nltk.downloader stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file format should be in .txt\n",
    "# filed = input()\n",
    "filed = r\"dataset\\kiran resume.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ResumeParser(filed).get_extracted_data()\n",
    "# print(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    doc = Document()\n",
    "    with open(filed, 'r') as file:\n",
    "        doc.add_paragraph(file.read())\n",
    "        doc.save(\"text.docx\")\n",
    "        data = ResumeParser(\"text.docx\").get_extracted_data()\n",
    "        print(data)\n",
    "except:\n",
    "    data = ResumeParser(filed).get_extracted_data()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyresparser import ResumeParser\n",
    "# data = ResumeParser(r\"dataset\\kiran resume.docx\", skills_file=r\"dataset\\skills.csv\").get_extracted_data()\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=hqu5EYMLCUw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Text Similarity in Python with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<spacy.lexeme.Lexeme at 0x14a338b01f8>,\n",
       " <spacy.lexeme.Lexeme at 0x14a1b82e0d8>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'red'\n",
    "w2 = 'blue'\n",
    "\n",
    "w1 = nlp.vocab[w1]\n",
    "w2 = nlp.vocab[w2]\n",
    "\n",
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438412"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.similarity(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = nlp(\"I believe in the god of the Bible\")\n",
    "s2 = nlp(\"I trust in a higher power of chrisrianity\")\n",
    "s3 = nlp(\"This weekend John will drink a beer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8469442263923321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.similarity(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7182935290755542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.similarity(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.692211795614116"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.similarity(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = nlp(\"Machine learning brings out the power of data in new ways, such as Facebook suggesting articles in your feed.\")\n",
    "s2 = nlp(\"This guide explains what machine learning is, how it is related to artificial intelligence, how it works and why it matters.\")\n",
    "s3 = nlp(\"Web development is the work involved in developing a website for the Internet (World Wide Web) or an intranet (a private network).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_verbs = \"\".join([token.lemma_ for token in s1 if token.pos == 'VERB'])\n",
    "s1_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_verbs = \"\".join([token.lemma_ for token in s1 if token.pos == 'VERB'])\n",
    "s1_adjs = \"\".join([token.lemma_ for token in s1 if token.pos == 'ADJ'])\n",
    "s1_nouns = \"\".join([token.lemma_ for token in s1 if token.pos == 'NOUN'])\n",
    "\n",
    "s2_verbs = \"\".join([token.lemma_ for token in s2 if token.pos == 'VERB'])\n",
    "s2_adjs = \"\".join([token.lemma_ for token in s2 if token.pos == 'ADJ'])\n",
    "s2_nouns = \"\".join([token.lemma_ for token in s2 if token.pos == 'NOUN'])\n",
    "\n",
    "s3_verbs = \"\".join([token.lemma_ for token in s3 if token.pos == 'VERB'])\n",
    "s3_adjs = \"\".join([token.lemma_ for token in s3 if token.pos == 'ADJ'])\n",
    "s3_nouns = \"\".join([token.lemma_ for token in s3 if token.pos == 'NOUN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(s1_verbs).similarity(nlp(s2_verbs)), nlp(s1_verbs).similarity(nlp(s2_verbs)), nlp(s2_verbs).similarity(nlp(s3_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(s1_adjs).similarity(nlp(s2_adjs)), nlp(s1_adjs).similarity(nlp(s2_adjs)), nlp(s2_adjs).similarity(nlp(s3_adjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(s1_nouns).similarity(nlp(s2_nouns)), nlp(s1_nouns).similarity(nlp(s2_nouns)), nlp(s2_nouns).similarity(nlp(s3_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikipedia\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import wikipedia\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shiva Star',\n",
       " 'The League',\n",
       " 'Nilakanta (Hinduism)',\n",
       " 'Baidyanath Temple',\n",
       " 'Karaikal Kailasanathar Temple',\n",
       " 'Vishnu Sahasranama',\n",
       " 'King Ezekiel',\n",
       " 'RRR (soundtrack)',\n",
       " 'Godavari River',\n",
       " 'Varanasi']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"Load Shiva\"\n",
    "keywords = wikipedia.search(title)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WikipediaPage 'Shiva Star'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = wikipedia.page(keywords[0])\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shiva Star, originally just SHIVA, is a high-powered pulsed-power research device located at the Air Force Research Laboratory on the Kirtland Air Force Base in Albuquerque, New Mexico. The device was originally built in the 1970s for high-power X-ray research, was later re-directed to studies for the Strategic Defense Initiative (SDI), and is now being used for magnetized target fusion research. Shiva Star was named after the Hindu god Shiva, partly because its prototype originally had four \"arms\"; it later got six \"arms\".\\n\\n\\n== Topics of research ==\\n\\n\\n=== Spacecraft propulsion ===\\nResearch at Princeton University in using Z-Pinch devices as a potential space propulsion device led to the exploration of the resulting x-ray production. This led directly to the original SHIVA effort in 1971. In these experiments a thin foil of a \"high-Z\" metal (lead, uranium, etc.) was rapidly compressed magnetically by dumping the output of capacitor banks into magnetic coils. As it was first built in 1974, SHIVA I consisted of four banks of capacitors arranged in a cross shape with the experimental chamber in the middle. The capacitors held 1 MJ at 100 kV, able to discharge them in 1 μs. Early experiments were hampered by problems with the implosion, but by 1976 successful implosions were being carried out. The capacitor banks were then upgraded to 1.9 MJ at 120 kV in 1979, becoming Shiva II. Another upgrade followed in 1982, adding two more capacitor banks, thereby changing the shape from a cross to a star, resulting in the current Shiva Star device. Shiva Star was also used as a dense plasma focus driver in the mid-80s, and as an experimental magnetic driver for conventional projectiles in the late-80s.\\n\\n\\n=== Plasma weapon ===\\n\\nShiva Star was also used to develop an experimental weapon known as MARAUDER for the SDI effort between 1989 and 1995. The idea appears to have been to create compact toroids of high-density plasma that would be ejected from the device using a massive magnetic pulse. The plasma projectiles would be shot at a speed expected to be 3000 km/s in 1995 and 10,000 km/s (3.3% of the speed of light) by 2000. A shot has the energy of 2,27 kg of TNT exploding.  Doughnut-shaped rings of plasma and balls of lightning exploded with devastating thermal and mechanical effects when hitting their target  and produced pulse of electromagnetic radiation that could scramble electronics, the energy would shower the interior of the target with high-energy x-rays that would potentially destroy the electronics inside. The tests cost a few million dollars a year. The project became classified, and no information about the fate of the project has been published after 1995.\\n\\n\\n=== Fusion ===\\nShiva Star was most recently revived for work in fusion research. A relatively new technique, magnetized target fusion, compresses a small plasma load with an imploding metal foil. Shiva Star\\'s 10 MJ capacitor banks were perfect for this role, and starting in 2007 the new FRCHX experiment has been using Shiva Star with 1 mm thick aluminium foil that is accelerated to about 5 km/s.\\n\\n\\n== See also ==\\nDresden High Magnetic Field Laboratory\\nLINUS (fusion experiment)\\nMagnetized Target Fusion\\nNova (laser)\\n\\n\\n== References =='"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = page.content\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color = 'white',\n",
    "                     max_words = 300,\n",
    "                     stopwords = stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x289fb1459b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.generate(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x289fb1459b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud.to_file(\"output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
