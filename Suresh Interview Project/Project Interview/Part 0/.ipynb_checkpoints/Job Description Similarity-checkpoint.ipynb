{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Program to see how similar a resume is to a job description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3966 sha256=96c4c28a9b7ca17208ef6a53050d70d424d528b06a6094d1a76af98cd7becdc5\n",
      "  Stored in directory: c:\\users\\munge\\appdata\\local\\pip\\cache\\wheels\\66\\d7\\77\\4dc0e151e2ef19b5474722fd943e312603f10016baab494f7a\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=bkigzpBLN6o&t=11s\n",
    "# !pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIRAN KRUSHNAKANT MUNGEKAR\n",
      "\n",
      "mungekarkiran05@gmail.com | +91-8108412112 | linkedin.com/in/kirankmungekar | github.com/mungekarkiran\n",
      "\n",
      "SUMMARY\n",
      "\n",
      "Seeking a position to utilize my skills and abilities to achieve professional growth while being flexible, as well as to enhance my skills in order to contribute to the company's growth.\n",
      "\n",
      "\n",
      "\n",
      "EXPERIENCE\n",
      "\n",
      "\t\tThinkgestalt.Tech | Data Analyst \tDecember 2020 - Present \n",
      "\n",
      "\t\tCollaborated with 2 data analyst and 1 project head to implement and analyse given data.\n",
      "\n",
      "Analyse, clean and visualize different factors influencing the financial domain.\n",
      "\n",
      "Determine and back-test the factors leading to risk of the financial application. \n",
      "\n",
      "Contribute towards the development and deployment micro-services module for rapid, frequent and reliable delivery of large, complex applications.\n",
      "\n",
      "Create Rest API’s using Flask and Django framework and help to integrate with different applications.\n",
      "\n",
      "Develop visually impactful report on Jupyter notebook to transform data into meaningful information as a proof of concept.\n",
      "\n",
      "\n",
      "\n",
      "PROJECTS\n",
      "\n",
      "Automated Trading System | Thinkgestalt.Tech\n",
      "\n",
      "Created module based on functional approach and OOPs concepts using Python for Statistical analysis and Logical implementation of the system, Plotly for visualization.\n",
      "\n",
      "Contribute towards the development and deployment of micro-services based Rest API's in Flask framework with MySQL and MongoDB (NoSQL) database.\n",
      "\n",
      "Create application using Python, Flask, Rest API, MySQL, MongoDB, Micro-services, Postman.\n",
      "\n",
      "\n",
      "\n",
      "Lead Generation for Sales | Thinkgestalt.Tech\n",
      "\n",
      "Data scraped from the web to reach out and offer our products and services to other companies on B2B and B2C level.\n",
      "\n",
      "Handled the web scraping part which helped the sales team to connect to clients hence contributing to increase the revenue of the company by 2%.\n",
      "\n",
      "Created module using Python, BeautifulSoup, Selenium and MS Excel.\n",
      "\n",
      "\n",
      "\n",
      "Aqua Drone to Collect Floating Waste | Thakur College of Engineering and Technology\n",
      "\n",
      "An embedded aqua drone prototype created as an AI module integrate with mobile app to control and monitor the boat.\n",
      "\n",
      "Created as a proof of concept (POC) and the aim is to integrate the deep learning model with embedded system and increase the accuracy by 5%.\n",
      "\n",
      "Created module using Python, Flask, Rest API, Deep Learning, Firebase, Computer Vision and Raspberry Pi.\n",
      "\n",
      "\n",
      "\n",
      "Car for Smart Cities - Smart Car | St. John College of Engineering and Management \n",
      "\n",
      "A module of self-driving cars created as a prototype with the help of deep learning and computer vision.\n",
      "\n",
      "Created as a proof of concept (POC) and the aim is to implement CNN that will automatically drive a vehicle in a real time scenario with 89.72% accuracy.\n",
      "\n",
      "Created module using Python, Deep Learning, Computer Vision, and Raspberry Pi.  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKILLS\n",
      "\n",
      "Languages and Software tools\n",
      "\n",
      "Data Analysis\n",
      "\n",
      "Strength\n",
      "\n",
      "Python, HTML, CSS,\n",
      "\n",
      "MySQL, PostgreSQL, SQLite, \n",
      "\n",
      "MongoDB, Firebase,\n",
      "\n",
      "Flask, Django,\n",
      "\n",
      "Rest API services, \n",
      "\n",
      "Visual studio code,\n",
      "\n",
      "Raspberry Pi, Arduino.\n",
      "\n",
      "\n",
      "\n",
      "Web Collection / Scraping, \n",
      "\n",
      "Data Visualization,\n",
      "\n",
      "Data Wrangling, Mathematical and Statistical Analysis, \n",
      "\n",
      "Data Pre-processing,\n",
      "\n",
      "Exploratory Data Analysis.\n",
      "\n",
      "Time Management,\n",
      "\n",
      " Good Explainer, \n",
      "\n",
      "Self-Motivation, \n",
      "\n",
      "Problem Solving,  \n",
      "\n",
      "Ability to work as an individual as well as in a team, Research.\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "\tThakur College of Engineering and Technology | Master of Engineering (M.E.) \tMumbai | July 2019 - July 2021\n",
      "\n",
      "Master's in : Information Technology – (Data Science)\n",
      "\n",
      "CGPA : 9.78 / 10\n",
      "\n",
      "Relevant Work : Python, Flask, Django, Rest API, Machine Learning, Deep Learning.\n",
      "\n",
      "\n",
      "\n",
      "\tSt. John College of Engineering and Technology | Bachelor of Engineering (B.E.) \tMumbai | July 2015 - July 2018\n",
      "\n",
      "Bachelor's in : Information Technology\n",
      "\n",
      "CGPA : 7.87 / 10\n",
      "\n",
      "Relevant Work : Python, Flask, Rest API, Machine Learning, Deep Learning, Firebase, Raspberry Pi.\n",
      "\n",
      "\n",
      "\n",
      "\tSardar Vallabhbhai Patel Polytechnic | Diploma \tMumbai | July 2010 - July 2015\n",
      "\n",
      "Diploma in : Information Technology\n",
      "\n",
      "Grade : 65.74 %\n",
      "\n",
      "Relevant Work : Core Java, Embedded C, HTML5, CSS3, MySQL.\n",
      "\n",
      "\n",
      "\n",
      "\tUtkarsha Vidyalaya | SSC \tMaharashtra State Board | March 2010\n",
      "\n",
      "Grade : 72.00 %\n",
      "\n",
      "\n",
      "\n",
      "ACHIEVEMENT\n",
      "\n",
      "Participated in Paper Presentation - Design & Implementation of Car for Smart Cities - Intelligent Car Prototype (Springer Publication - Paper Code - 261)\n"
     ]
    }
   ],
   "source": [
    "# load data (resume and JD in .docx formate)\n",
    "resume = docx2txt.process(r'dataset/kiran resume.docx')\n",
    "\n",
    "# print resume\n",
    "print(resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist Intern - Summer 2023\n",
      "\n",
      "Ever dream of mining gold from big data? The LinkedIn Data Science team is looking for data junkies who love turning data into gold and who want to make an impact. You will work closely with our business partners in product, marketing and sales to mine insights from big data, and to impact business decisions. LinkedIn's reputable internship program is known for plentiful activities. Join us this summer!\n",
      "\n",
      "At LinkedIn, we trust each other to do our best work where it works best for us and our teams. This role offers a hybrid work option, meaning you can both work from home and commute to a LinkedIn office, depending on what’s best for you and when it is important for your team to be together.\n",
      "\n",
      "Responsibilities:\n",
      "• Analyze, mash-up, and mine massive amounts of data to extract useful business insights;\n",
      "• Work closely with data analytics staff and our business partners to analyze product performance and member engagement data to drive informed decisions;\n",
      "• Utilize data engineering tools to process big data in a scalable and automated fashion;\n",
      "• Design and build business KPI dashboards and data visualizations;\n",
      "• Develop presentation story and slides based on the analysis;\n",
      "• This is a full-time internship role based in Sunnyvale, CA, San Francisco, CA, or New York, NY\n",
      "• This internship will take place during Summer 2023\n",
      "\n",
      "\n",
      "Basic Qualifications:\n",
      "Currently pursuing a B.A./B.S. Degree or higher in a quantitative discipline: statistics, applied mathematics, operations research, computer science, management of information systems, engineering, economics or equivalent and returning to the program after the completion of the internship\n",
      "Experience with SQL or other relational databases.\n",
      "Experience in at least one programming language (eg. R, Python, Hive, Java, Ruby, Scala/Spark or Perl etc)\n",
      "\n",
      "Preferred Qualifications:\n",
      "Expected to complete degree by December 2024 or earlier\n",
      "Experience with data visualization tools (eg. Tableau, BI dashboarding, R visualization packages, etc.)\n",
      "Experience building front-end visualizations using JavaScript frameworks (eg. jQuery, Marionette, D3, or Highcharts).\n",
      "Experience in applied statistics and statistical modeling in at least one statistical software package, (eg. Advance R package, SAS, SPSS)\n",
      "Experience in Hadoop or other MapReduce paradigms and associated languages such as Pig and Hive;\n",
      "Ability to communicate findings clearly to both technical and non-technical audiences;\n",
      "Knowledge of Unix and Unix-like systems, git and review board.\n",
      "\n",
      "The pay range for this role is $50 to $60 USD per hour. Actual compensation packages are based on a wide array of factors unique to each candidate, including but not limited to skill set, years & depth of experience, certifications and specific office location. This may differ in other locations due to cost of labor considerations.\n",
      "\n",
      "\n",
      "Equal Opportunity Statement\n",
      "LinkedIn is committed to diversity in its workforce and is proud to be an equal opportunity employer. LinkedIn considers qualified applicants without regard to race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. LinkedIn is an Affirmative Action and Equal Opportunity Employer as described in our equal opportunity statement here: https://lnkd.in/equalemploymentopportunity2017. Please reference http://www1.eeoc.gov/employers/upload/eeoc_self_print_poster.pdf and https://www.dol.gov/ofccp/regs/compliance/posters/pdf/OFCCP_EEO_Supplement_Final_JRF_QA_508c.pdf for more information.\n",
      "\n",
      "LinkedIn is committed to offering an inclusive and accessible experience for all job seekers, including individuals with disabilities. Our goal is to foster an inclusive and accessible workplace where everyone has the opportunity to be successful.\n",
      "\n",
      "If you need a reasonable accommodation to search for a job opening, apply for a position, or participate in the interview process, connect with us at accommodations@linkedin.com and describe the specific accommodation requested for a disability-related limitation.\n",
      "\n",
      "Reasonable accommodations are modifications or adjustments to the application or hiring process that would enable you to fully participate in that process. Examples of reasonable accommodations include but are not limited to:\n",
      "\n",
      "-Documents in alternate formats or read aloud to you\n",
      "-Having interviews in an accessible location\n",
      "-Being accompanied by a service dog\n",
      "-Having a sign language interpreter present for the interview\n",
      "\n",
      "A request for an accommodation will be responded to within three business days. However, non-disability related requests, such as following up on an application, will not receive a response.\n",
      "\n",
      "LinkedIn will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by LinkedIn, or (c) consistent with LinkedIn's legal duty to furnish information.\n",
      "\n",
      "Pay Transparency Policy Statement\n",
      "As a federal contractor, LinkedIn follows the Pay Transparency and non-discrimination provisions described at this link: https://lnkd.in/paytransparency.\n",
      "\n",
      "Global Data Privacy Notice for Job Candidates\n",
      "This document provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://lnkd.in/GlobalDataPrivacyNotice\n"
     ]
    }
   ],
   "source": [
    "job_decription = docx2txt.process(r'dataset/JD1.docx')\n",
    "\n",
    "# print JD\n",
    "print(job_decription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of text\n",
    "text = [resume, job_decription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 339)\t1\n",
      "  (0, 344)\t1\n",
      "  (0, 400)\t1\n",
      "  (0, 402)\t1\n",
      "  (0, 268)\t1\n",
      "  (0, 121)\t3\n",
      "  (0, 20)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 360)\t1\n",
      "  (0, 306)\t9\n",
      "  (0, 340)\t1\n",
      "  (0, 264)\t1\n",
      "  (0, 401)\t1\n",
      "  (0, 575)\t1\n",
      "  (0, 541)\t1\n",
      "  (0, 462)\t1\n",
      "  (0, 597)\t19\n",
      "  (0, 615)\t1\n",
      "  (0, 403)\t2\n",
      "  (0, 551)\t3\n",
      "  (0, 53)\t30\n",
      "  (0, 21)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 478)\t1\n",
      "  (0, 274)\t2\n",
      "  :\t:\n",
      "  (1, 136)\t1\n",
      "  (1, 140)\t1\n",
      "  (1, 353)\t1\n",
      "  (1, 201)\t1\n",
      "  (1, 259)\t1\n",
      "  (1, 603)\t3\n",
      "  (1, 460)\t1\n",
      "  (1, 236)\t1\n",
      "  (1, 141)\t1\n",
      "  (1, 244)\t1\n",
      "  (1, 185)\t1\n",
      "  (1, 488)\t1\n",
      "  (1, 359)\t1\n",
      "  (1, 447)\t1\n",
      "  (1, 266)\t1\n",
      "  (1, 471)\t1\n",
      "  (1, 412)\t1\n",
      "  (1, 100)\t1\n",
      "  (1, 190)\t1\n",
      "  (1, 487)\t1\n",
      "  (1, 68)\t1\n",
      "  (1, 629)\t1\n",
      "  (1, 277)\t1\n",
      "  (1, 452)\t1\n",
      "  (1, 267)\t1\n"
     ]
    }
   ],
   "source": [
    "# CounterVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text)\n",
    "\n",
    "# print count_matrix\n",
    "print(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.62322557]\n",
      " [0.62322557 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# print similarity score\n",
    "similarity_score = cosine_similarity(count_matrix)\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your reseme maches about 62.32% of the Job Description.\n"
     ]
    }
   ],
   "source": [
    "# get the match percent.\n",
    "match_percent = round(similarity_score[1][0]*100,2)\n",
    "print(f\"Your reseme maches about {match_percent}% of the Job Description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
