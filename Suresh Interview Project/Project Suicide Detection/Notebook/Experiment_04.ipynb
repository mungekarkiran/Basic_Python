{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0205e9",
   "metadata": {},
   "source": [
    "# Traditional ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23c6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1072c6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>anymore</th>\n",
       "      <th>anyone</th>\n",
       "      <th>anything</th>\n",
       "      <th>around</th>\n",
       "      <th>back</th>\n",
       "      <th>bad</th>\n",
       "      <th>better</th>\n",
       "      <th>cant</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>Topic_1</th>\n",
       "      <th>Topic_2</th>\n",
       "      <th>Topic_3</th>\n",
       "      <th>Topic_4</th>\n",
       "      <th>Topic_5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.367680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.289972</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.685770</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.898189</td>\n",
       "      <td>0.025003</td>\n",
       "      <td>0.026267</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.034386</td>\n",
       "      <td>0.033334</td>\n",
       "      <td>0.237204</td>\n",
       "      <td>0.661744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.051255</td>\n",
       "      <td>0.050010</td>\n",
       "      <td>0.796905</td>\n",
       "      <td>0.051509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064171</td>\n",
       "      <td>0.064511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.269270</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.722341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>0.029708</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>0.603239</td>\n",
       "      <td>0.309907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.838003</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.041150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.731766</td>\n",
       "      <td>0.066676</td>\n",
       "      <td>0.067825</td>\n",
       "      <td>0.067066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.186823</td>\n",
       "      <td>0.084033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084835</td>\n",
       "      <td>0.065762</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.329361</td>\n",
       "      <td>0.662549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025824</td>\n",
       "      <td>0.898356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232050 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        also    always   anymore    anyone  anything    around      back  \\\n",
       "0        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.367680   \n",
       "1        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4        0.0  0.000000  0.064171  0.064511  0.000000  0.000000  0.000000   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "232045   0.0  0.000000  0.000000  0.000000  0.499350  0.000000  0.000000   \n",
       "232046   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "232047   0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "232048   0.0  0.000000  0.000000  0.000000  0.081052  0.186823  0.084033   \n",
       "232049   0.0  0.446812  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "             bad    better      cant  ...  way  work  would  year   Topic_1  \\\n",
       "0       0.000000  0.000000  0.000000  ...    1     0      0     0  0.008016   \n",
       "1       0.000000  0.000000  0.000000  ...    0     0      0     0  0.025000   \n",
       "2       0.484986  0.000000  0.000000  ...    0     0      0     1  0.033333   \n",
       "3       0.000000  0.000000  0.000000  ...    0     0      0     0  0.050321   \n",
       "4       0.000000  0.000000  0.000000  ...    0     0      0     3  0.002778   \n",
       "...          ...       ...       ...  ...  ...   ...    ...   ...       ...   \n",
       "232045  0.000000  0.000000  0.000000  ...    0     0      0     0  0.028572   \n",
       "232046  0.000000  0.000000  0.000000  ...    0     0      0     0  0.040000   \n",
       "232047  0.000000  0.000000  0.000000  ...    0     0      0     0  0.066667   \n",
       "232048  0.000000  0.084835  0.065762  ...    0     0      4     0  0.002667   \n",
       "232049  0.000000  0.000000  0.000000  ...    0     0      0     0  0.025000   \n",
       "\n",
       "         Topic_2   Topic_3   Topic_4   Topic_5  class  \n",
       "0       0.289972  0.008001  0.008242  0.685770      1  \n",
       "1       0.898189  0.025003  0.026267  0.025541      0  \n",
       "2       0.034386  0.033334  0.237204  0.661744      0  \n",
       "3       0.051255  0.050010  0.796905  0.051509      1  \n",
       "4       0.269270  0.002778  0.002833  0.722341      1  \n",
       "...          ...       ...       ...       ...    ...  \n",
       "232045  0.029708  0.028575  0.603239  0.309907      0  \n",
       "232046  0.838003  0.040002  0.040844  0.041150      0  \n",
       "232047  0.731766  0.066676  0.067825  0.067066      0  \n",
       "232048  0.002757  0.002667  0.329361  0.662549      1  \n",
       "232049  0.025820  0.025000  0.025824  0.898356      0  \n",
       "\n",
       "[232050 rows x 206 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all data\n",
    "dataset_dir = os.path.join('..', 'Dataset')\n",
    "tfidf_features_data_path = os.path.join(dataset_dir, 'tfidf_features_50.csv')\n",
    "tfidf_df = pd.read_csv(tfidf_features_data_path)\n",
    "tfidf_df = tfidf_df.drop(['class'], axis = 1)\n",
    "\n",
    "ngram_df_features_data_path = os.path.join(dataset_dir, 'ngram_df_features_50.csv')\n",
    "ngram_df = pd.read_csv(ngram_df_features_data_path)\n",
    "ngram_df = ngram_df.drop(['class'], axis = 1)\n",
    "\n",
    "lda_df_features_data_path = os.path.join(dataset_dir, 'lda_df_features_50.csv')\n",
    "lda_df = pd.read_csv(lda_df_features_data_path)\n",
    "# lda_df = lda_df.drop(['class'], axis = 1)\n",
    "\n",
    "data = pd.concat([tfidf_df, ngram_df, lda_df], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3302acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = data.drop(['class'], axis = 1), data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78c39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "x_train, x_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5cec89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluation metrics dictionary\n",
    "evaluation_metrics = {}\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model_name, y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    evaluation_metrics[model_name] = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred),\n",
    "        'kappa': cohen_kappa_score(y_true, y_pred),\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} - Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(f\"Accuracy : {accuracy_score(y_true, y_pred)} \\n\")\n",
    "    print(f\"Loss : {1 - accuracy_score(y_true, y_pred)} \\n\")\n",
    "    print(f\"Cohen Kappa Score : {cohen_kappa_score(y_true, y_pred)} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3120841",
   "metadata": {},
   "source": [
    "### Traditional ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dcc0783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProjectWork\\Basic_Python\\Suresh Interview Project\\Project Suicide Detection\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87     23204\n",
      "           1       0.89      0.84      0.86     23206\n",
      "\n",
      "    accuracy                           0.87     46410\n",
      "   macro avg       0.87      0.87      0.87     46410\n",
      "weighted avg       0.87      0.87      0.87     46410\n",
      "\n",
      "Accuracy : 0.8681534152122388 \n",
      "\n",
      "Loss : 0.13184658478776123 \n",
      "\n",
      "Cohen Kappa Score : 0.7363074268854618 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train, y_train)\n",
    "y_pred = log_reg.predict(x_val)\n",
    "evaluate_model(\"Logistic Regression\", y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b676a242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83     23204\n",
      "           1       0.80      0.89      0.85     23206\n",
      "\n",
      "    accuracy                           0.84     46410\n",
      "   macro avg       0.84      0.84      0.84     46410\n",
      "weighted avg       0.84      0.84      0.84     46410\n",
      "\n",
      "Accuracy : 0.8370609782374488 \n",
      "\n",
      "Loss : 0.16293902176255115 \n",
      "\n",
      "Cohen Kappa Score : 0.6741203932608677 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_val)\n",
    "evaluate_model(\"Naive Bayes\", y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0b25a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82     23204\n",
      "           1       0.82      0.80      0.81     23206\n",
      "\n",
      "    accuracy                           0.81     46410\n",
      "   macro avg       0.81      0.81      0.81     46410\n",
      "weighted avg       0.81      0.81      0.81     46410\n",
      "\n",
      "Accuracy : 0.8127774186597716 \n",
      "\n",
      "Loss : 0.1872225813402284 \n",
      "\n",
      "Cohen Kappa Score : 0.6255554075340606 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_val)\n",
    "evaluate_model(\"Decision Tree\", y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e0a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87     23204\n",
      "           1       0.87      0.85      0.86     23206\n",
      "\n",
      "    accuracy                           0.86     46410\n",
      "   macro avg       0.86      0.86      0.86     46410\n",
      "weighted avg       0.86      0.86      0.86     46410\n",
      "\n",
      "Accuracy : 0.8645335057099763 \n",
      "\n",
      "Loss : 0.13546649429002366 \n",
      "\n",
      "Cohen Kappa Score : 0.7290672861403743 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_val)\n",
    "evaluate_model(\"Random Forest\", y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6f0417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87     23204\n",
      "           1       0.91      0.79      0.85     23206\n",
      "\n",
      "    accuracy                           0.86     46410\n",
      "   macro avg       0.86      0.86      0.86     46410\n",
      "weighted avg       0.86      0.86      0.86     46410\n",
      "\n",
      "Accuracy : 0.8562809739280327 \n",
      "\n",
      "Loss : 0.1437190260719673 \n",
      "\n",
      "Cohen Kappa Score : 0.7125636864423426 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred = svm.predict(x_val)\n",
    "evaluate_model(\"SVM\", y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0a76b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87     23204\n",
      "           1       0.89      0.85      0.87     23206\n",
      "\n",
      "    accuracy                           0.87     46410\n",
      "   macro avg       0.87      0.87      0.87     46410\n",
      "weighted avg       0.87      0.87      0.87     46410\n",
      "\n",
      "Accuracy : 0.8713639301874596 \n",
      "\n",
      "Loss : 0.1286360698125404 \n",
      "\n",
      "Cohen Kappa Score : 0.7427284427896291 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts, labels = data.drop(['class'], axis = 1), data['class']\n",
    "texts, labels = texts.values, labels.values\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7614ac84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'accuracy': 0.8681534152122388,\n",
       "  'precision': np.float64(0.8885705189430118),\n",
       "  'recall': np.float64(0.841894337671292),\n",
       "  'f1_score': np.float64(0.8646029252317837),\n",
       "  'kappa': np.float64(0.7363074268854618),\n",
       "  'classification_report': {'0': {'precision': 0.8497727551897801,\n",
       "    'recall': 0.8944147560765385,\n",
       "    'f1-score': 0.8715224557498897,\n",
       "    'support': 23204.0},\n",
       "   '1': {'precision': 0.8885705189430118,\n",
       "    'recall': 0.841894337671292,\n",
       "    'f1-score': 0.8646029252317837,\n",
       "    'support': 23206.0},\n",
       "   'accuracy': 0.8681534152122388,\n",
       "   'macro avg': {'precision': 0.869171637066396,\n",
       "    'recall': 0.8681545468739152,\n",
       "    'f1-score': 0.8680626904908367,\n",
       "    'support': 46410.0},\n",
       "   'weighted avg': {'precision': 0.8691724730449297,\n",
       "    'recall': 0.8681534152122388,\n",
       "    'f1-score': 0.8680625413951566,\n",
       "    'support': 46410.0}}},\n",
       " 'Naive Bayes': {'accuracy': 0.8370609782374488,\n",
       "  'precision': np.float64(0.8033193733519467),\n",
       "  'recall': np.float64(0.8927001637507541),\n",
       "  'f1_score': np.float64(0.8456545699473405),\n",
       "  'kappa': np.float64(0.6741203932608677),\n",
       "  'classification_report': {'0': {'precision': 0.8792551643875473,\n",
       "    'recall': 0.7814169970694708,\n",
       "    'f1-score': 0.8274540227262356,\n",
       "    'support': 23204.0},\n",
       "   '1': {'precision': 0.8033193733519467,\n",
       "    'recall': 0.8927001637507541,\n",
       "    'f1-score': 0.8456545699473405,\n",
       "    'support': 23206.0},\n",
       "   'accuracy': 0.8370609782374488,\n",
       "   'macro avg': {'precision': 0.841287268869747,\n",
       "    'recall': 0.8370585804101125,\n",
       "    'f1-score': 0.836554296336788,\n",
       "    'support': 46410.0},\n",
       "   'weighted avg': {'precision': 0.8412856326751545,\n",
       "    'recall': 0.8370609782374488,\n",
       "    'f1-score': 0.8365546885054418,\n",
       "    'support': 46410.0}}},\n",
       " 'Decision Tree': {'accuracy': 0.8127774186597716,\n",
       "  'precision': np.float64(0.8242573151664061),\n",
       "  'recall': np.float64(0.7950960958372835),\n",
       "  'f1_score': np.float64(0.8094141387554561),\n",
       "  'kappa': np.float64(0.6255554075340606),\n",
       "  'classification_report': {'0': {'precision': 0.8020811654526535,\n",
       "    'recall': 0.8304602654714704,\n",
       "    'f1-score': 0.8160240530182726,\n",
       "    'support': 23204.0},\n",
       "   '1': {'precision': 0.8242573151664061,\n",
       "    'recall': 0.7950960958372835,\n",
       "    'f1-score': 0.8094141387554561,\n",
       "    'support': 23206.0},\n",
       "   'accuracy': 0.8127774186597716,\n",
       "   'macro avg': {'precision': 0.8131692403095299,\n",
       "    'recall': 0.812778180654377,\n",
       "    'f1-score': 0.8127190958868644,\n",
       "    'support': 46410.0},\n",
       "   'weighted avg': {'precision': 0.81316971814081,\n",
       "    'recall': 0.8127774186597716,\n",
       "    'f1-score': 0.8127189534625106,\n",
       "    'support': 46410.0}}},\n",
       " 'Random Forest': {'accuracy': 0.8645335057099763,\n",
       "  'precision': np.float64(0.8733395118937287),\n",
       "  'recall': np.float64(0.8527535982073602),\n",
       "  'f1_score': np.float64(0.8629237981031287),\n",
       "  'kappa': np.float64(0.7290672861403743),\n",
       "  'classification_report': {'0': {'precision': 0.8561323733737527,\n",
       "    'recall': 0.8763144285468023,\n",
       "    'f1-score': 0.8661058460227877,\n",
       "    'support': 23204.0},\n",
       "   '1': {'precision': 0.8733395118937287,\n",
       "    'recall': 0.8527535982073602,\n",
       "    'f1-score': 0.8629237981031287,\n",
       "    'support': 23206.0},\n",
       "   'accuracy': 0.8645335057099763,\n",
       "   'macro avg': {'precision': 0.8647359426337407,\n",
       "    'recall': 0.8645340133770812,\n",
       "    'f1-score': 0.8645148220629582,\n",
       "    'support': 46410.0},\n",
       "   'weighted avg': {'precision': 0.8647363133973374,\n",
       "    'recall': 0.8645335057099763,\n",
       "    'f1-score': 0.8645147534991159,\n",
       "    'support': 46410.0}}},\n",
       " 'SVM': {'accuracy': 0.8562809739280327,\n",
       "  'precision': np.float64(0.914477641868859),\n",
       "  'recall': np.float64(0.7860898043609411),\n",
       "  'f1_score': np.float64(0.8454372711683737),\n",
       "  'kappa': np.float64(0.7125636864423426),\n",
       "  'classification_report': {'0': {'precision': 0.8124102486584537,\n",
       "    'recall': 0.9264781934149284,\n",
       "    'f1-score': 0.8657028953408771,\n",
       "    'support': 23204.0},\n",
       "   '1': {'precision': 0.914477641868859,\n",
       "    'recall': 0.7860898043609411,\n",
       "    'f1-score': 0.8454372711683737,\n",
       "    'support': 23206.0},\n",
       "   'accuracy': 0.8562809739280327,\n",
       "   'macro avg': {'precision': 0.8634439452636564,\n",
       "    'recall': 0.8562839988879347,\n",
       "    'f1-score': 0.8555700832546254,\n",
       "    'support': 46410.0},\n",
       "   'weighted avg': {'precision': 0.8634461445179811,\n",
       "    'recall': 0.8562809739280327,\n",
       "    'f1-score': 0.8555696465895924,\n",
       "    'support': 46410.0}}},\n",
       " 'XGBoost': {'accuracy': 0.8713639301874596,\n",
       "  'precision': np.float64(0.8919767124533794),\n",
       "  'recall': np.float64(0.8450831681461691),\n",
       "  'f1_score': np.float64(0.8678969729155602),\n",
       "  'kappa': np.float64(0.7427284427896291),\n",
       "  'classification_report': {'0': {'precision': 0.8528087127415657,\n",
       "    'recall': 0.8976469574211343,\n",
       "    'f1-score': 0.8746535651297556,\n",
       "    'support': 23204.0},\n",
       "   '1': {'precision': 0.8919767124533794,\n",
       "    'recall': 0.8450831681461691,\n",
       "    'f1-score': 0.8678969729155602,\n",
       "    'support': 23206.0},\n",
       "   'accuracy': 0.8713639301874596,\n",
       "   'macro avg': {'precision': 0.8723927125974725,\n",
       "    'recall': 0.8713650627836518,\n",
       "    'f1-score': 0.871275269022658,\n",
       "    'support': 46410.0},\n",
       "   'weighted avg': {'precision': 0.8723935565535104,\n",
       "    'recall': 0.8713639301874596,\n",
       "    'f1-score': 0.8712751234378223,\n",
       "    'support': 46410.0}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80732f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
