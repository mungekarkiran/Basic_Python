{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Chronic_Kidney_Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Chronic_Kidney_Disease Data Set](https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "> Chronic kidney disease is one of the most common diseases facing humans, as well as one of the most dangerous. This disease is defined as a long-term condition in which the kidneys do not work as they should. It is a common condition often associated with aging. It can infect anyone, but it is more common in most countries such as those in South Asia.\n",
    "\n",
    "> We used data containing features for reasons that indicate chronic kidney disease. We used machine learning algorithms to help classify the person with or without this disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# to read .arff files\n",
    "from scipy.io import arff\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# display all the columns of the dataframes\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/kidney_disease.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show information a bout data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping id column\n",
    "df.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names to make it more user-friendly\n",
    "\n",
    "df.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',\n",
    "              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',\n",
    "              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',\n",
    "              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',\n",
    "              'aanemia', 'class']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting necessary columns to numerical type \n",
    "df['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')\n",
    "df['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')\n",
    "df['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')\n",
    "\n",
    "# we can show the data after made convert for unssesary columns to numerical\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking at unique values\n",
    "for col in df.columns:\n",
    "    print(f\"{col} has {df[col].unique()} | \\n{len(df[col].unique())} values\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a replace for incorect value \n",
    "\n",
    "df['diabetes_mellitus'].replace(to_replace = {'\\tno':'no','\\tyes':'yes',' yes':'yes'},inplace=True)\n",
    "\n",
    "df['coronary_artery_disease'] = df['coronary_artery_disease'].replace(to_replace = '\\tno', value='no')\n",
    "\n",
    "df['class'] = df['class'].replace(to_replace = {'ckd\\t': 'ckd', 'notckd': 'not ckd'})\n",
    "\n",
    "# ckd == 0 and not ckd == 1\n",
    "df['class'] = df['class'].map({'ckd': 0, 'not ckd': 1})\n",
    "df['class'] = pd.to_numeric(df['class'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['diabetes_mellitus', 'coronary_artery_disease', 'class']\n",
    "\n",
    "for col in cols:\n",
    "    print(f\"{col} has {df[col].unique()} | \\n{len(df[col].unique())} values\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot to show the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting categorical and numerical columns\n",
    "\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "num_cols = [col for col in df.columns if df[col].dtype != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at unique values in categorical columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"{col} has {df[col].unique()} values\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking numerical features distribution\n",
    "plt.figure(figsize = (30, 25))\n",
    "plotnumber = 1\n",
    "for column in num_cols:\n",
    "    if plotnumber <= len(num_cols): # 14:\n",
    "        ax = plt.subplot(5, 3, plotnumber)\n",
    "        sns.distplot(df[column], color='blue')\n",
    "        plt.xlabel(column)\n",
    "        \n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at categorical columns\n",
    "\n",
    "plt.figure(figsize = (30, 35))\n",
    "plotnumber = 1\n",
    "for column in cat_cols:\n",
    "    if plotnumber <= len(cat_cols): # 11:\n",
    "        ax = plt.subplot(6, 2, plotnumber)\n",
    "        sns.countplot(df[column], palette = 'Set2', color='black')\n",
    "        plt.xlabel(column)\n",
    "        \n",
    "    plotnumber += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation the crro\n",
    "cor=df.corr()\n",
    "plt.figure(figsize = (20, 15))\n",
    "sns.heatmap(cor, annot = True, linewidths = 1, linecolor = 'lightgrey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"age\", y=\"blood_pressure\", color=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"age\", y=\"sugar\", color=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"age\", y=\"haemoglobin\", color=\"class\", marginal_y=\"violin\", marginal_x=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x=\"age\", y=\"bacteria\", color=\"class\", marginal_y=\"violin\", marginal_x=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(df, y=\"age\", x=\"sugar\", color=\"class\", box=True, points=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df, x='age', y='hypertension', z='sugar', color='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values and correct it\n",
    "\n",
    "df.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_value_imputation(feature):\n",
    "    random_sample = df[feature].dropna().sample(df[feature].isna().sum())\n",
    "    random_sample.index = df[df[feature].isnull()].index\n",
    "    df.loc[df[feature].isnull(), feature] = random_sample\n",
    "    \n",
    "def impute_mode(feature):\n",
    "    mode = df[feature].mode()[0]\n",
    "    df[feature] = df[feature].fillna(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling num_cols null values using random sampling method\n",
    "\n",
    "for col in num_cols:\n",
    "    random_value_imputation(col)\n",
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling \"red_blood_cells\" and \"pus_cell\" using random sampling method and rest of cat_cols using mode imputation\n",
    "\n",
    "random_value_imputation('red_blood_cells')\n",
    "random_value_imputation('pus_cell')\n",
    "\n",
    "for col in cat_cols:\n",
    "    impute_mode(col)\n",
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(f\"{col} has {df[col].nunique()} categories\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since all of our columns have two classes, we can use the label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the machien Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting in X,y\n",
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of X_train\",X_train.shape)\n",
    "print(\"The shape of X_test\",X_test.shape)\n",
    "print(\"The shape of X_train\",y_train.shape)\n",
    "print(\"The shape of X_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 10)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model_RF Train Score is : ' , classifier.score(X_train, y_train))\n",
    "print('model_RF Test Score is : ' , classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy_score:\", round((accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "\n",
    "print(\"Loss:\", round((1-accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "\n",
    "print(\"Cohen_kappa_score:\", round((cohen_kappa_score(y_test, y_pred))*100,2),'%')\n",
    "\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# print(\"confusion_matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"confusion_matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8,6) # WH\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), \n",
    "           annot=True,\n",
    "                 linewidths = 2,\n",
    "                linecolor = \"blue\",\n",
    "                center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns, X_test.iloc[0,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict([X_test.iloc[0,:].values])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = np.array([27,60,1.009,2,2,1,1,0,0,42,102,45,5.5,10,10,25,2500,3.6,0,0,0,0,0,0])\n",
    "\n",
    "y_pred = classifier.predict([input_list])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'rf_Classifier.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns, X_test.iloc[1,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.iloc[1,:], y_test.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC \n",
    "# svm_classifier = SVC()  \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "svm_classifier = DecisionTreeClassifier(criterion='entropy', random_state=101)\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model_SVM Train Score is : ' , svm_classifier.score(X_train, y_train))\n",
    "print('model_SVM Test Score is : ' , svm_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy_score:\", round((accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "\n",
    "print(\"Loss:\", round((1-accuracy_score(y_test, y_pred))*100,2),'%')\n",
    "\n",
    "print(\"Cohen_kappa_score:\", round((cohen_kappa_score(y_test, y_pred))*100,2),'%')\n",
    "\n",
    "print(\"Classification_report:\\n\",metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# print(\"confusion_matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"confusion_matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8,6) # WH\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),             \n",
    "            annot=True,\n",
    "            linewidths = 2,\n",
    "            linecolor = \"blue\",\n",
    "            center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict([X_test.iloc[0,:].values])\n",
    "y_pred, y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = np.array([27,60,1.009,2,2,1,1,0,0,42,102,45,5.5,10,10,25,2500,3.6,0,0,0,0,0,0])\n",
    "\n",
    "y_pred = classifier.predict([input_list])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'dt_Classifier.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
